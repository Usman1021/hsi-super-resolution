{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c73964",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from spectral import open_image\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, Activation, Add, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54d101",
   "metadata": {},
   "source": [
    "## Preprocess dataset with band grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3da9f5-77c9-49a9-8088-2fc05d01b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741333115.353754 3035959 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_hr shape: (5902, 144, 144, 6)\n",
      "X_validation_hr shape: (843, 144, 144, 6)\n",
      "X_test_hr shape: (1687, 144, 144, 6)\n",
      "X_train_lr shape: (5902, 72, 72, 6)\n",
      "X_validation_lr shape: (843, 72, 72, 6)\n",
      "X_test_lr shape: (1687, 72, 72, 6)\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the path to the hyperspectral data\n",
    "header_file = \"HyperspecVNIR_Chikusei_20140729.hdr\"\n",
    "\n",
    "# Load the hyperspectral data\n",
    "img = open_image(header_file)\n",
    "data = img.load()\n",
    "\n",
    "# Parameters\n",
    "patch_size = (144, 144)  # Size of patches to extract\n",
    "test_size = 0.2  # Proportion of data for testing\n",
    "validation_size = 0.1  # Proportion of data for validation\n",
    "downscale_factor = 2  # Factor to downscale patches\n",
    "nodata_value = 15000.0  # Value that indicates \"no data\"\n",
    "group_size = 6  # Group size for spectral bands\n",
    "overlap_size = 2  # Overlap size for grouped bands\n",
    "\n",
    "# Function to group bands into overlapping subgroups\n",
    "def group_bands_with_overlap(data, group_size=6, overlap_size=2):\n",
    "    height, width, bands = data.shape\n",
    "    step_size = group_size - overlap_size  # Calculate step size based on overlap\n",
    "    grouped_data = []\n",
    "\n",
    "    # Create overlapping groups of bands\n",
    "    for g in range(0, bands - group_size + 1, step_size):\n",
    "        group = data[:, :, g:g + group_size]\n",
    "        grouped_data.append(group)\n",
    "    \n",
    "    return np.array(grouped_data)\n",
    "\n",
    "# Function to extract and downscale patches from hyperspectral data\n",
    "def extract_and_downscale_patches(data, patch_size, downscale_factor, nodata_value=0):\n",
    "    patches_hr = []\n",
    "    patches_lr = []\n",
    "    height, width, bands = data.shape\n",
    "\n",
    "    for i in range(0, height - patch_size[0] + 1, patch_size[0]):\n",
    "        for j in range(0, width - patch_size[1] + 1, patch_size[1]):\n",
    "            patch_hr = data[i:i + patch_size[0], j:j + patch_size[1], :]\n",
    "\n",
    "            # Check for nodata_value and skip patch extraction if present\n",
    "            if np.any(patch_hr == nodata_value):\n",
    "                continue\n",
    "            \n",
    "            patch_lr = tf.image.resize(patch_hr, \n",
    "                                       [patch_size[0] // downscale_factor, patch_size[1] // downscale_factor], \n",
    "                                       method='bilinear')\n",
    "            patches_hr.append(patch_hr)\n",
    "            patches_lr.append(patch_lr.numpy())  # Convert tensor to numpy\n",
    "\n",
    "    return np.array(patches_hr), np.array(patches_lr)\n",
    "\n",
    "# Group bands into overlapping subgroups\n",
    "grouped_data = group_bands_with_overlap(data, group_size=group_size, overlap_size=overlap_size)\n",
    "\n",
    "# Extract and downscale patches for all groups\n",
    "all_patches_hr = []\n",
    "all_patches_lr = []\n",
    "\n",
    "for group in grouped_data:\n",
    "    patches_hr, patches_lr = extract_and_downscale_patches(group, patch_size, downscale_factor, nodata_value=nodata_value)\n",
    "    all_patches_hr.append(patches_hr)\n",
    "    all_patches_lr.append(patches_lr)\n",
    "\n",
    "# Concatenate patches from all groups\n",
    "all_patches_hr = np.concatenate(all_patches_hr, axis=0)\n",
    "all_patches_lr = np.concatenate(all_patches_lr, axis=0)\n",
    "\n",
    "# Calculate the number of patches\n",
    "num_patches = len(all_patches_hr)\n",
    "\n",
    "# Calculate sizes for training, validation, and testing sets\n",
    "train_size = int((1 - test_size - validation_size) * num_patches)\n",
    "validation_size = int(validation_size * num_patches)\n",
    "test_size = num_patches - (train_size + validation_size)  # Explicit calculation of test size\n",
    "\n",
    "# Shuffle indices for splitting the data\n",
    "indices = np.arange(num_patches)\n",
    "np.random.shuffle(indices)\n",
    "all_patches_hr = all_patches_hr[indices]\n",
    "all_patches_lr = all_patches_lr[indices]\n",
    "\n",
    "# Split into training, validation, and testing sets\n",
    "X_train_hr, X_validation_hr, X_test_hr = np.split(all_patches_hr, [train_size, train_size + validation_size])\n",
    "X_train_lr, X_validation_lr, X_test_lr = np.split(all_patches_lr, [train_size, train_size + validation_size])\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"X_train_hr shape:\", X_train_hr.shape)\n",
    "print(\"X_validation_hr shape:\", X_validation_hr.shape)\n",
    "print(\"X_test_hr shape:\", X_test_hr.shape)\n",
    "\n",
    "print(\"X_train_lr shape:\", X_train_lr.shape)\n",
    "print(\"X_validation_lr shape:\", X_validation_lr.shape)\n",
    "print(\"X_test_lr shape:\", X_test_lr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0559e6f1",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9afece-281b-46c2-896c-1b7165765280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Spatial–Spectral Gradient Loss Function\n",
    "def spatial_spectral_gradient_loss(y_true, y_pred):\n",
    "    mse_loss = K.mean(K.square(y_true - y_pred))\n",
    "    \n",
    "    def spatial_gradient_loss(y_true, y_pred):\n",
    "        grad_y_true_x = y_true[:, :, 1:, :] - y_true[:, :, :-1, :]\n",
    "        grad_y_pred_x = y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :]\n",
    "        grad_y_true_y = y_true[:, 1:, :, :] - y_true[:, :-1, :, :]\n",
    "        grad_y_pred_y = y_pred[:, 1:, :, :] - y_pred[:, :-1, :, :]\n",
    "        \n",
    "        loss_x = K.mean(K.square(grad_y_true_x - grad_y_pred_x))\n",
    "        loss_y = K.mean(K.square(grad_y_true_y - grad_y_pred_y))\n",
    "        \n",
    "        return loss_x + loss_y\n",
    "\n",
    "    def spectral_gradient_loss(y_true, y_pred):\n",
    "        grad_y_true_spectral = y_true[:, :, :, 1:] - y_true[:, :, :, :-1]\n",
    "        grad_y_pred_spectral = y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1]\n",
    "        return K.mean(K.square(grad_y_true_spectral - grad_y_pred_spectral))\n",
    "\n",
    "    spatial_loss = spatial_gradient_loss(y_true, y_pred)\n",
    "    spectral_loss = spectral_gradient_loss(y_true, y_pred)\n",
    "    \n",
    "    total_loss = mse_loss + 0.1 * spatial_loss + 0.1 * spectral_loss\n",
    "    return total_loss\n",
    "\n",
    "# Residual Block\n",
    "def residual_block(x, filters=32):\n",
    "    res = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    res = BatchNormalization()(res)\n",
    "    res = Activation('relu')(res)\n",
    "    res = Conv2D(filters, (3, 3), padding='same')(res)\n",
    "    res = BatchNormalization()(res)\n",
    "    return Add()([x, res])\n",
    "\n",
    "# Spectral–Spatial Block\n",
    "def spectral_spatial_block(x, filters=32):\n",
    "    spatial = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    spatial = BatchNormalization()(spatial)\n",
    "    spatial = Activation('relu')(spatial)\n",
    "    \n",
    "    spectral = Conv2D(filters, (1, 1), padding='same')(x)\n",
    "    spectral = BatchNormalization()(spectral)\n",
    "    spectral = Activation('relu')(spectral)\n",
    "    \n",
    "    spatial = Conv2D(filters, (1, 1), padding='same')(spatial)\n",
    "    \n",
    "    combined = Concatenate(axis=-1)([spatial, spectral])\n",
    "    return combined\n",
    "\n",
    "# Spectral Unmixing Block\n",
    "def spectral_unmixing_block(x, num_endmembers=40):\n",
    "    x = Conv2D(num_endmembers, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    return x\n",
    "\n",
    "# General Upsampling Block (Supports Transpose and Standard Upsampling)\n",
    "def upsample_block(x, filters, scale=2, use_transpose=True):\n",
    "    if use_transpose:\n",
    "        x = Conv2DTranspose(filters, (3, 3), strides=(scale, scale), padding='same')(x)\n",
    "    else:\n",
    "        x = UpSampling2D(size=(scale, scale))(x)\n",
    "        x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Build Model with Configurable Upsampling\n",
    "def build_hybrid_sr_model(input_shape, num_endmembers=40, use_transpose=True):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(32, (9, 9), padding='same')(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    for _ in range(50):\n",
    "        x = residual_block(x)\n",
    "    \n",
    "    x = spectral_spatial_block(x)\n",
    "    \n",
    "    x_unmixed = spectral_unmixing_block(x, num_endmembers)\n",
    "    \n",
    "    x_concat = Concatenate(axis=-1)([x, x_unmixed])\n",
    "    \n",
    "    x_up = upsample_block(x_concat, filters=64, scale=2, use_transpose=use_transpose)  # 2x upscaling\n",
    "#    x_up = upsample_block(x_up, filters=32, scale=2, use_transpose=use_transpose)  # 4x upscaling\n",
    "    \n",
    "    x_out = Conv2D(input_shape[-1], (3, 3), padding='same')(x_up)\n",
    "    x_out = Activation('linear')(x_out)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x_out)\n",
    "    return model\n",
    "\n",
    "# Define input shape and build model\n",
    "input_shape = (72, 72, 6)\n",
    "num_endmembers = 40\n",
    "use_transpose = True \n",
    "\n",
    "hybrid_sr_model = build_hybrid_sr_model(input_shape, num_endmembers=num_endmembers, use_transpose=use_transpose)\n",
    "\n",
    "# Compile the model with the custom loss function\n",
    "hybrid_sr_model.compile(optimizer='adam', loss=spatial_spectral_gradient_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c27558",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531448ae-e872-4b62-a802-e1754e3049cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741333185.645278 3036066 service.cc:148] XLA service 0x7fb6c8039b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741333185.646157 3036066 service.cc:156]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2025-03-07 09:39:47.317665: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741333192.674023 3036066 cuda_dnn.cc:529] Loaded cuDNN version 90501\n",
      "2025-03-07 09:39:57.634675: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,32,72,72]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,32,72,72]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-07 09:39:58.118204: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,144,144]{3,2,1,0}, f32[6,64,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   3/1476\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 39ms/step - loss: 0.9665    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741333209.308172 3036066 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1475/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 09:41:02.840838: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[2,32,72,72]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,32,72,72]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-07 09:41:03.017261: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[2,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,64,144,144]{3,2,1,0}, f32[6,64,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 09:41:21.782226: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[3,32,72,72]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,32,72,72]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-07 09:41:21.928700: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[3,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,64,144,144]{3,2,1,0}, f32[6,64,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 50ms/step - loss: 0.0205 - val_loss: 6.9600e-04\n",
      "Epoch 2/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 3/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 4/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 9.4775e-04 - val_loss: 3.7003e-04\n",
      "Epoch 5/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.5120e-04 - val_loss: 0.0027\n",
      "Epoch 6/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 3.5937e-04\n",
      "Epoch 7/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.1706e-04 - val_loss: 3.3672e-04\n",
      "Epoch 8/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 3.9204e-04 - val_loss: 3.5094e-04\n",
      "Epoch 9/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 3.3581e-04 - val_loss: 2.3264e-04\n",
      "Epoch 10/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 3.0049e-04 - val_loss: 1.9570e-04\n",
      "Epoch 11/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 2.7021e-04 - val_loss: 2.1974e-04\n",
      "Epoch 12/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 2.4725e-04 - val_loss: 1.6021e-04\n",
      "Epoch 13/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 2.4874e-04 - val_loss: 2.3946e-04\n",
      "Epoch 14/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 2.1098e-04 - val_loss: 1.6281e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.9954e-04 - val_loss: 1.9777e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 2.1431e-04 - val_loss: 1.3878e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.9771e-04 - val_loss: 1.8821e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.8333e-04 - val_loss: 1.6061e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.7402e-04 - val_loss: 1.5784e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.7076e-04 - val_loss: 1.5284e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.7301e-04 - val_loss: 1.8021e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.6846e-04 - val_loss: 1.3354e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.7317e-04 - val_loss: 1.4520e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.5334e-04 - val_loss: 1.9080e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.5017e-04 - val_loss: 1.4317e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.5064e-04 - val_loss: 1.7072e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.5248e-04 - val_loss: 1.2214e-04\n",
      "Epoch 28/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.4740e-04 - val_loss: 1.2754e-04\n",
      "Epoch 29/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.3984e-04 - val_loss: 1.5937e-04\n",
      "Epoch 30/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.4515e-04 - val_loss: 1.1427e-04\n",
      "Epoch 31/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 1.4221e-04 - val_loss: 1.4433e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 1.3477e-04 - val_loss: 1.1673e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.4166e-04 - val_loss: 1.2804e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.3377e-04 - val_loss: 1.1428e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.3181e-04 - val_loss: 1.1744e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.2808e-04 - val_loss: 1.2257e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.2629e-04 - val_loss: 1.2631e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.2607e-04 - val_loss: 1.0928e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.3415e-04 - val_loss: 1.1261e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.2161e-04 - val_loss: 1.0624e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.2139e-04 - val_loss: 1.1795e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.1981e-04 - val_loss: 1.2730e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.1941e-04 - val_loss: 1.2517e-04\n",
      "Epoch 44/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.2601e-04 - val_loss: 1.1230e-04\n",
      "Epoch 45/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.1593e-04 - val_loss: 1.0309e-04\n",
      "Epoch 46/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.1715e-04 - val_loss: 1.1383e-04\n",
      "Epoch 47/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.1439e-04 - val_loss: 1.0193e-04\n",
      "Epoch 48/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.1418e-04 - val_loss: 1.1482e-04\n",
      "Epoch 49/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.1976e-04 - val_loss: 1.0386e-04\n",
      "Epoch 50/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.1224e-04 - val_loss: 1.0544e-04\n",
      "Epoch 51/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.1000e-04 - val_loss: 1.0147e-04\n",
      "Epoch 52/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.1468e-04 - val_loss: 1.0218e-04\n",
      "Epoch 53/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.1113e-04 - val_loss: 1.0384e-04\n",
      "Epoch 54/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.0854e-04 - val_loss: 1.1776e-04\n",
      "Epoch 55/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.1141e-04 - val_loss: 1.0259e-04\n",
      "Epoch 56/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.0670e-04 - val_loss: 1.0415e-04\n",
      "Epoch 57/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.0511e-04 - val_loss: 1.0480e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 1.1208e-04 - val_loss: 1.0115e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.0396e-04 - val_loss: 9.8532e-05\n",
      "Epoch 60/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.0706e-04 - val_loss: 1.0255e-04\n",
      "Epoch 61/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.0852e-04 - val_loss: 1.0240e-04\n",
      "Epoch 62/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.0256e-04 - val_loss: 1.1736e-04\n",
      "Epoch 63/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.0741e-04 - val_loss: 9.6919e-05\n",
      "Epoch 64/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.0009e-04 - val_loss: 1.2305e-04\n",
      "Epoch 65/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.0794e-04 - val_loss: 1.1052e-04\n",
      "Epoch 66/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.0042e-04 - val_loss: 9.6012e-05\n",
      "Epoch 67/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 9.9238e-05 - val_loss: 9.3760e-05\n",
      "Epoch 68/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 1.0385e-04 - val_loss: 1.0217e-04\n",
      "Epoch 69/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 9.8835e-05 - val_loss: 1.0201e-04\n",
      "Epoch 70/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 9.7671e-05 - val_loss: 1.4154e-04\n",
      "Epoch 71/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.0463e-04 - val_loss: 9.6038e-05\n",
      "Epoch 72/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 9.7353e-05 - val_loss: 1.2466e-04\n",
      "Epoch 73/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 1.0160e-04 - val_loss: 9.3568e-05\n",
      "Epoch 74/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 9.6171e-05 - val_loss: 8.9741e-05\n",
      "Epoch 75/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 9.3765e-05 - val_loss: 1.1082e-04\n",
      "Epoch 76/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 1.0011e-04 - val_loss: 9.1769e-05\n",
      "Epoch 77/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 9.2525e-05 - val_loss: 8.9435e-05\n",
      "Epoch 78/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 9.2434e-05 - val_loss: 9.0544e-05\n",
      "Epoch 79/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 9.8956e-05 - val_loss: 9.4641e-05\n",
      "Epoch 80/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 9.3028e-05 - val_loss: 9.5314e-05\n",
      "Epoch 81/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 9.4008e-05 - val_loss: 9.3340e-05\n",
      "Epoch 82/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 9.0468e-05 - val_loss: 1.4857e-04\n",
      "Epoch 83/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 9.4452e-05 - val_loss: 8.8324e-05\n",
      "Epoch 84/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 8.8877e-05 - val_loss: 8.7116e-05\n",
      "Epoch 85/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 9.5004e-05 - val_loss: 8.9996e-05\n",
      "Epoch 86/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 8.9362e-05 - val_loss: 8.6978e-05\n",
      "Epoch 87/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 8.8825e-05 - val_loss: 9.1876e-05\n",
      "Epoch 88/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 9.2069e-05 - val_loss: 9.0695e-05\n",
      "Epoch 89/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 8.7477e-05 - val_loss: 9.7794e-05\n",
      "Epoch 90/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 8.8498e-05 - val_loss: 8.5647e-05\n",
      "Epoch 91/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 9.0136e-05 - val_loss: 8.7946e-05\n",
      "Epoch 92/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 9.0441e-05 - val_loss: 9.1145e-05\n",
      "Epoch 93/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 9.4367e-05 - val_loss: 1.0173e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 8.7843e-05 - val_loss: 8.6781e-05\n",
      "Epoch 95/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 9.0157e-05 - val_loss: 1.0096e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 8.6763e-05 - val_loss: 8.3975e-05\n",
      "Epoch 97/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 8.5818e-05 - val_loss: 9.4790e-05\n",
      "Epoch 98/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 8.7126e-05 - val_loss: 8.6364e-05\n",
      "Epoch 99/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 8.6958e-05 - val_loss: 9.4406e-05\n",
      "Epoch 100/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 8.6719e-05 - val_loss: 8.1529e-05\n",
      "Epoch 101/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 8.2732e-05 - val_loss: 8.5027e-05\n",
      "Epoch 102/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 8.3607e-05 - val_loss: 1.0100e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 8.9124e-05 - val_loss: 8.4115e-05\n",
      "Epoch 104/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 8.3510e-05 - val_loss: 1.0130e-04\n",
      "Epoch 105/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 8.1679e-05 - val_loss: 8.3770e-05\n",
      "Epoch 106/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 8.2800e-05 - val_loss: 1.0026e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 8.6591e-05 - val_loss: 8.1231e-05\n",
      "Epoch 108/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 8.4157e-05 - val_loss: 9.6869e-05\n",
      "Epoch 109/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 8.3364e-05 - val_loss: 7.9874e-05\n",
      "Epoch 110/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.9693e-05 - val_loss: 9.9549e-05\n",
      "Epoch 111/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 8.2803e-05 - val_loss: 8.2439e-05\n",
      "Epoch 112/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 8.1954e-05 - val_loss: 8.7226e-05\n",
      "Epoch 113/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.9839e-05 - val_loss: 1.0147e-04\n",
      "Epoch 114/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 8.6832e-05 - val_loss: 9.6317e-05\n",
      "Epoch 115/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.9098e-05 - val_loss: 9.2096e-05\n",
      "Epoch 116/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 8.0613e-05 - val_loss: 7.6440e-05\n",
      "Epoch 117/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 34ms/step - loss: 7.8734e-05 - val_loss: 7.9228e-05\n",
      "Epoch 118/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 8.0323e-05 - val_loss: 8.9736e-05\n",
      "Epoch 119/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.8678e-05 - val_loss: 7.7334e-05\n",
      "Epoch 120/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.9937e-05 - val_loss: 8.4908e-05\n",
      "Epoch 121/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.7084e-05 - val_loss: 7.7417e-05\n",
      "Epoch 122/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 7.8884e-05 - val_loss: 9.3019e-05\n",
      "Epoch 123/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.6954e-05 - val_loss: 8.1497e-05\n",
      "Epoch 124/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.6814e-05 - val_loss: 8.0817e-05\n",
      "Epoch 125/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.8193e-05 - val_loss: 7.7815e-05\n",
      "Epoch 126/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.7943e-05 - val_loss: 8.5473e-05\n",
      "Epoch 127/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.5633e-05 - val_loss: 7.6577e-05\n",
      "Epoch 128/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.8225e-05 - val_loss: 7.8632e-05\n",
      "Epoch 129/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.4398e-05 - val_loss: 7.8221e-05\n",
      "Epoch 130/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.5837e-05 - val_loss: 9.2090e-05\n",
      "Epoch 131/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 7.5701e-05 - val_loss: 8.8334e-05\n",
      "Epoch 132/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.7771e-05 - val_loss: 9.1294e-05\n",
      "Epoch 133/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 7.4149e-05 - val_loss: 9.4825e-05\n",
      "Epoch 134/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 7.7490e-05 - val_loss: 8.4464e-05\n",
      "Epoch 135/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.2864e-05 - val_loss: 7.9961e-05\n",
      "Epoch 136/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.4497e-05 - val_loss: 9.3948e-05\n",
      "Epoch 137/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.1670e-05 - val_loss: 7.6979e-05\n",
      "Epoch 138/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 7.7123e-05 - val_loss: 8.3651e-05\n",
      "Epoch 139/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 7.1484e-05 - val_loss: 7.4302e-05\n",
      "Epoch 140/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 7.5186e-05 - val_loss: 7.3788e-05\n",
      "Epoch 141/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.8635e-05 - val_loss: 8.0429e-05\n",
      "Epoch 142/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.4568e-05 - val_loss: 8.4460e-05\n",
      "Epoch 143/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.3013e-05 - val_loss: 9.2171e-05\n",
      "Epoch 144/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.0650e-05 - val_loss: 7.0924e-05\n",
      "Epoch 145/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.3314e-05 - val_loss: 7.4782e-05\n",
      "Epoch 146/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.3216e-05 - val_loss: 8.0062e-05\n",
      "Epoch 147/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.3291e-05 - val_loss: 8.0094e-05\n",
      "Epoch 148/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 7.1946e-05 - val_loss: 1.9391e-04\n",
      "Epoch 149/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 8.5651e-05 - val_loss: 8.0968e-05\n",
      "Epoch 150/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.0117e-05 - val_loss: 1.0107e-04\n",
      "Epoch 151/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.1025e-05 - val_loss: 7.2807e-05\n",
      "Epoch 152/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.3247e-05 - val_loss: 7.1490e-05\n",
      "Epoch 153/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.9920e-05 - val_loss: 7.1498e-05\n",
      "Epoch 154/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.8571e-05 - val_loss: 7.3382e-05\n",
      "Epoch 155/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.9375e-05 - val_loss: 7.1208e-05\n",
      "Epoch 156/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.0586e-05 - val_loss: 8.2110e-05\n",
      "Epoch 157/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 7.1362e-05 - val_loss: 7.4054e-05\n",
      "Epoch 158/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.8225e-05 - val_loss: 6.8906e-05\n",
      "Epoch 159/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.7998e-05 - val_loss: 6.9616e-05\n",
      "Epoch 160/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.8234e-05 - val_loss: 6.9605e-05\n",
      "Epoch 161/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.7201e-05 - val_loss: 8.2371e-05\n",
      "Epoch 162/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.7102e-05 - val_loss: 6.9660e-05\n",
      "Epoch 163/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.9385e-05 - val_loss: 7.2613e-05\n",
      "Epoch 164/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.2138e-05 - val_loss: 6.8450e-05\n",
      "Epoch 165/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.6696e-05 - val_loss: 7.5200e-05\n",
      "Epoch 166/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.9950e-05 - val_loss: 8.1323e-05\n",
      "Epoch 167/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.7033e-05 - val_loss: 7.1261e-05\n",
      "Epoch 168/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.7517e-05 - val_loss: 6.8961e-05\n",
      "Epoch 169/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.5870e-05 - val_loss: 7.2913e-05\n",
      "Epoch 170/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.7054e-05 - val_loss: 7.3321e-05\n",
      "Epoch 171/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.4979e-05 - val_loss: 7.1963e-05\n",
      "Epoch 172/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 7.2102e-05 - val_loss: 7.3782e-05\n",
      "Epoch 173/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.7635e-05 - val_loss: 7.9200e-05\n",
      "Epoch 174/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.8614e-05 - val_loss: 6.7087e-05\n",
      "Epoch 175/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.5976e-05 - val_loss: 7.0926e-05\n",
      "Epoch 176/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.9311e-05 - val_loss: 6.9421e-05\n",
      "Epoch 177/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.4095e-05 - val_loss: 6.7418e-05\n",
      "Epoch 178/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.6695e-05 - val_loss: 6.7607e-05\n",
      "Epoch 179/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.6783e-05 - val_loss: 7.3872e-05\n",
      "Epoch 180/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.6450e-05 - val_loss: 8.1306e-05\n",
      "Epoch 181/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.7476e-05 - val_loss: 6.7736e-05\n",
      "Epoch 182/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.4490e-05 - val_loss: 6.5865e-05\n",
      "Epoch 183/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.4052e-05 - val_loss: 6.5673e-05\n",
      "Epoch 184/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.3864e-05 - val_loss: 6.6704e-05\n",
      "Epoch 185/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.6795e-05 - val_loss: 6.8703e-05\n",
      "Epoch 186/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.6213e-05 - val_loss: 7.4565e-05\n",
      "Epoch 187/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.6668e-05 - val_loss: 6.5297e-05\n",
      "Epoch 188/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.3561e-05 - val_loss: 6.7482e-05\n",
      "Epoch 189/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 7.3426e-05 - val_loss: 6.5582e-05\n",
      "Epoch 190/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.2289e-05 - val_loss: 7.0337e-05\n",
      "Epoch 191/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.2202e-05 - val_loss: 6.5349e-05\n",
      "Epoch 192/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.7607e-05 - val_loss: 6.7134e-05\n",
      "Epoch 193/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 6.2846e-05 - val_loss: 6.5075e-05\n",
      "Epoch 194/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 6.4602e-05 - val_loss: 6.9611e-05\n",
      "Epoch 195/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.3044e-05 - val_loss: 9.1378e-05\n",
      "Epoch 196/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.4203e-05 - val_loss: 6.4019e-05\n",
      "Epoch 197/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.2395e-05 - val_loss: 6.9005e-05\n",
      "Epoch 198/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.2746e-05 - val_loss: 9.3654e-05\n",
      "Epoch 199/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.7014e-05 - val_loss: 6.8122e-05\n",
      "Epoch 200/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.1409e-05 - val_loss: 8.1523e-05\n",
      "Epoch 201/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.3962e-05 - val_loss: 1.0921e-04\n",
      "Epoch 202/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.5657e-05 - val_loss: 7.3469e-05\n",
      "Epoch 203/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.4816e-05 - val_loss: 7.3198e-05\n",
      "Epoch 204/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.5431e-05 - val_loss: 6.5990e-05\n",
      "Epoch 205/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.3109e-05 - val_loss: 6.5632e-05\n",
      "Epoch 206/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 6.1378e-05 - val_loss: 6.4649e-05\n",
      "Epoch 207/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.0234e-05 - val_loss: 6.3939e-05\n",
      "Epoch 208/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.2381e-05 - val_loss: 8.0894e-05\n",
      "Epoch 209/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.2018e-05 - val_loss: 7.0194e-05\n",
      "Epoch 210/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.5945e-05 - val_loss: 6.3318e-05\n",
      "Epoch 211/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.0094e-05 - val_loss: 7.2777e-05\n",
      "Epoch 212/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.8705e-05 - val_loss: 7.5537e-05\n",
      "Epoch 213/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.0757e-05 - val_loss: 6.2303e-05\n",
      "Epoch 214/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.1674e-05 - val_loss: 7.8774e-05\n",
      "Epoch 215/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.2587e-05 - val_loss: 6.7103e-05\n",
      "Epoch 216/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.0118e-05 - val_loss: 6.6121e-05\n",
      "Epoch 217/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.3980e-05 - val_loss: 6.5155e-05\n",
      "Epoch 218/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.0933e-05 - val_loss: 6.1614e-05\n",
      "Epoch 219/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.2918e-05 - val_loss: 6.6173e-05\n",
      "Epoch 220/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.0556e-05 - val_loss: 6.1722e-05\n",
      "Epoch 221/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.9551e-05 - val_loss: 6.2250e-05\n",
      "Epoch 222/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.0721e-05 - val_loss: 8.7567e-05\n",
      "Epoch 223/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.2564e-05 - val_loss: 6.4867e-05\n",
      "Epoch 224/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.9571e-05 - val_loss: 6.9728e-05\n",
      "Epoch 225/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.2078e-05 - val_loss: 6.2731e-05\n",
      "Epoch 226/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.8244e-05 - val_loss: 7.4612e-05\n",
      "Epoch 227/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.9255e-05 - val_loss: 6.7101e-05\n",
      "Epoch 228/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.0888e-05 - val_loss: 6.2691e-05\n",
      "Epoch 229/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.8467e-05 - val_loss: 6.3257e-05\n",
      "Epoch 230/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.8155e-05 - val_loss: 7.5978e-05\n",
      "Epoch 231/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.8741e-05 - val_loss: 6.4962e-05\n",
      "Epoch 232/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.8191e-05 - val_loss: 6.2100e-05\n",
      "Epoch 233/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.1375e-05 - val_loss: 6.9605e-05\n",
      "Epoch 234/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.8143e-05 - val_loss: 6.1069e-05\n",
      "Epoch 235/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.7798e-05 - val_loss: 6.4879e-05\n",
      "Epoch 236/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.8484e-05 - val_loss: 7.8331e-05\n",
      "Epoch 237/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 6.0810e-05 - val_loss: 6.0623e-05\n",
      "Epoch 238/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.6729e-05 - val_loss: 6.7591e-05\n",
      "Epoch 239/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.8326e-05 - val_loss: 6.2673e-05\n",
      "Epoch 240/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.0889e-05 - val_loss: 6.1192e-05\n",
      "Epoch 241/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.6805e-05 - val_loss: 6.0954e-05\n",
      "Epoch 242/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.7350e-05 - val_loss: 6.5027e-05\n",
      "Epoch 243/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.7989e-05 - val_loss: 6.5927e-05\n",
      "Epoch 244/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 34ms/step - loss: 5.7389e-05 - val_loss: 8.4054e-05\n",
      "Epoch 245/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 34ms/step - loss: 5.9473e-05 - val_loss: 6.7004e-05\n",
      "Epoch 246/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.6665e-05 - val_loss: 6.8341e-05\n",
      "Epoch 247/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.8099e-05 - val_loss: 7.0424e-05\n",
      "Epoch 248/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.7547e-05 - val_loss: 6.4586e-05\n",
      "Epoch 249/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.7430e-05 - val_loss: 6.5861e-05\n",
      "Epoch 250/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.7312e-05 - val_loss: 6.5247e-05\n",
      "Epoch 251/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.7011e-05 - val_loss: 6.5828e-05\n",
      "Epoch 252/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.8169e-05 - val_loss: 8.1039e-05\n",
      "Epoch 253/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.9089e-05 - val_loss: 6.0614e-05\n",
      "Epoch 254/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.6047e-05 - val_loss: 6.1167e-05\n",
      "Epoch 255/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.5590e-05 - val_loss: 6.7898e-05\n",
      "Epoch 256/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.6966e-05 - val_loss: 7.3968e-05\n",
      "Epoch 257/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.8842e-05 - val_loss: 6.1187e-05\n",
      "Epoch 258/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.5465e-05 - val_loss: 6.0646e-05\n",
      "Epoch 259/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.0974e-05 - val_loss: 5.9559e-05\n",
      "Epoch 260/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.5087e-05 - val_loss: 6.1154e-05\n",
      "Epoch 261/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.8262e-05 - val_loss: 5.9257e-05\n",
      "Epoch 262/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 34ms/step - loss: 5.5965e-05 - val_loss: 6.2670e-05\n",
      "Epoch 263/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.7021e-05 - val_loss: 6.1089e-05\n",
      "Epoch 264/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.5971e-05 - val_loss: 6.3652e-05\n",
      "Epoch 265/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.7224e-05 - val_loss: 6.1178e-05\n",
      "Epoch 266/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.4777e-05 - val_loss: 6.9506e-05\n",
      "Epoch 267/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.4979e-05 - val_loss: 6.7061e-05\n",
      "Epoch 268/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.7803e-05 - val_loss: 6.6275e-05\n",
      "Epoch 269/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.5429e-05 - val_loss: 6.1118e-05\n",
      "Epoch 270/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.4658e-05 - val_loss: 6.8285e-05\n",
      "Epoch 271/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 6.0804e-05 - val_loss: 7.7998e-05\n",
      "Epoch 272/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.6216e-05 - val_loss: 6.0547e-05\n",
      "Epoch 273/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.5994e-05 - val_loss: 5.9430e-05\n",
      "Epoch 274/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.5006e-05 - val_loss: 5.8281e-05\n",
      "Epoch 275/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.5053e-05 - val_loss: 6.7804e-05\n",
      "Epoch 276/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.5042e-05 - val_loss: 6.3924e-05\n",
      "Epoch 277/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.5533e-05 - val_loss: 5.9793e-05\n",
      "Epoch 278/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.4101e-05 - val_loss: 6.0483e-05\n",
      "Epoch 279/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.5157e-05 - val_loss: 6.0898e-05\n",
      "Epoch 280/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.4024e-05 - val_loss: 5.9867e-05\n",
      "Epoch 281/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.4352e-05 - val_loss: 6.6109e-05\n",
      "Epoch 282/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.7622e-05 - val_loss: 6.2959e-05\n",
      "Epoch 283/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.4559e-05 - val_loss: 6.0099e-05\n",
      "Epoch 284/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.6442e-05 - val_loss: 1.0269e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 6.4806e-05 - val_loss: 7.1966e-05\n",
      "Epoch 286/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.4992e-05 - val_loss: 5.8375e-05\n",
      "Epoch 287/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 34ms/step - loss: 5.5711e-05 - val_loss: 5.7537e-05\n",
      "Epoch 288/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.3698e-05 - val_loss: 5.7301e-05\n",
      "Epoch 289/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.6690e-05 - val_loss: 6.9279e-05\n",
      "Epoch 290/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.4864e-05 - val_loss: 6.1561e-05\n",
      "Epoch 291/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.6109e-05 - val_loss: 5.8621e-05\n",
      "Epoch 292/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.2752e-05 - val_loss: 5.9873e-05\n",
      "Epoch 293/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.3958e-05 - val_loss: 6.5549e-05\n",
      "Epoch 294/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.5255e-05 - val_loss: 5.9030e-05\n",
      "Epoch 295/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.6125e-05 - val_loss: 6.0792e-05\n",
      "Epoch 296/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.3840e-05 - val_loss: 6.1776e-05\n",
      "Epoch 297/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.3363e-05 - val_loss: 5.8566e-05\n",
      "Epoch 298/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.3358e-05 - val_loss: 6.8307e-05\n",
      "Epoch 299/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.4544e-05 - val_loss: 6.5896e-05\n",
      "Epoch 300/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.4926e-05 - val_loss: 6.0284e-05\n",
      "Epoch 301/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.2736e-05 - val_loss: 6.0215e-05\n",
      "Epoch 302/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.3200e-05 - val_loss: 6.0125e-05\n",
      "Epoch 303/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.3506e-05 - val_loss: 5.7999e-05\n",
      "Epoch 304/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.2911e-05 - val_loss: 5.8644e-05\n",
      "Epoch 305/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.3703e-05 - val_loss: 8.0450e-05\n",
      "Epoch 306/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.8386e-05 - val_loss: 6.7793e-05\n",
      "Epoch 307/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.3434e-05 - val_loss: 5.8683e-05\n",
      "Epoch 308/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.4291e-05 - val_loss: 5.7501e-05\n",
      "Epoch 309/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.2502e-05 - val_loss: 5.7085e-05\n",
      "Epoch 310/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2813e-05 - val_loss: 5.7463e-05\n",
      "Epoch 311/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.4763e-05 - val_loss: 6.1291e-05\n",
      "Epoch 312/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.2731e-05 - val_loss: 5.7726e-05\n",
      "Epoch 313/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2430e-05 - val_loss: 6.1276e-05\n",
      "Epoch 314/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.4171e-05 - val_loss: 6.2071e-05\n",
      "Epoch 315/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2503e-05 - val_loss: 5.7070e-05\n",
      "Epoch 316/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2080e-05 - val_loss: 6.0752e-05\n",
      "Epoch 317/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.4200e-05 - val_loss: 6.7756e-05\n",
      "Epoch 318/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.3271e-05 - val_loss: 5.9809e-05\n",
      "Epoch 319/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2070e-05 - val_loss: 6.2569e-05\n",
      "Epoch 320/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2490e-05 - val_loss: 5.6798e-05\n",
      "Epoch 321/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.4977e-05 - val_loss: 5.7477e-05\n",
      "Epoch 322/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2070e-05 - val_loss: 6.1485e-05\n",
      "Epoch 323/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 31ms/step - loss: 5.1722e-05 - val_loss: 5.6100e-05\n",
      "Epoch 324/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.2790e-05 - val_loss: 5.9611e-05\n",
      "Epoch 325/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.2650e-05 - val_loss: 5.7250e-05\n",
      "Epoch 326/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2607e-05 - val_loss: 6.0040e-05\n",
      "Epoch 327/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.4595e-05 - val_loss: 6.3504e-05\n",
      "Epoch 328/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.3321e-05 - val_loss: 6.1193e-05\n",
      "Epoch 329/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.2246e-05 - val_loss: 5.6774e-05\n",
      "Epoch 330/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.5215e-05 - val_loss: 5.6037e-05\n",
      "Epoch 331/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.0451e-05 - val_loss: 5.6733e-05\n",
      "Epoch 332/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.2090e-05 - val_loss: 5.7275e-05\n",
      "Epoch 333/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.3819e-05 - val_loss: 9.0133e-05\n",
      "Epoch 334/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.4942e-05 - val_loss: 5.7319e-05\n",
      "Epoch 335/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.0771e-05 - val_loss: 5.8064e-05\n",
      "Epoch 336/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.0675e-05 - val_loss: 5.9190e-05\n",
      "Epoch 337/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.1595e-05 - val_loss: 5.8805e-05\n",
      "Epoch 338/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.1444e-05 - val_loss: 5.7683e-05\n",
      "Epoch 339/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.3190e-05 - val_loss: 5.5263e-05\n",
      "Epoch 340/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.2913e-05 - val_loss: 5.5527e-05\n",
      "Epoch 341/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.0708e-05 - val_loss: 6.1315e-05\n",
      "Epoch 342/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.3428e-05 - val_loss: 5.7467e-05\n",
      "Epoch 343/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.0530e-05 - val_loss: 5.5656e-05\n",
      "Epoch 344/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0668e-05 - val_loss: 5.8307e-05\n",
      "Epoch 345/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.1846e-05 - val_loss: 5.9521e-05\n",
      "Epoch 346/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 34ms/step - loss: 5.2204e-05 - val_loss: 8.4659e-05\n",
      "Epoch 347/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.2447e-05 - val_loss: 5.6480e-05\n",
      "Epoch 348/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.0755e-05 - val_loss: 5.5905e-05\n",
      "Epoch 349/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.0902e-05 - val_loss: 5.4399e-05\n",
      "Epoch 350/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.0656e-05 - val_loss: 5.6147e-05\n",
      "Epoch 351/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0769e-05 - val_loss: 5.6452e-05\n",
      "Epoch 352/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.0270e-05 - val_loss: 5.4966e-05\n",
      "Epoch 353/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0709e-05 - val_loss: 5.6094e-05\n",
      "Epoch 354/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.0757e-05 - val_loss: 5.6142e-05\n",
      "Epoch 355/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.0855e-05 - val_loss: 5.7620e-05\n",
      "Epoch 356/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.5350e-05 - val_loss: 7.8766e-05\n",
      "Epoch 357/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.2029e-05 - val_loss: 5.5788e-05\n",
      "Epoch 358/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0248e-05 - val_loss: 6.0367e-05\n",
      "Epoch 359/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.1185e-05 - val_loss: 5.4979e-05\n",
      "Epoch 360/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.0752e-05 - val_loss: 5.7039e-05\n",
      "Epoch 361/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.3998e-05 - val_loss: 8.3905e-05\n",
      "Epoch 362/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 5.4866e-05 - val_loss: 5.5446e-05\n",
      "Epoch 363/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9478e-05 - val_loss: 5.4152e-05\n",
      "Epoch 364/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0080e-05 - val_loss: 5.6922e-05\n",
      "Epoch 365/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.0119e-05 - val_loss: 5.5537e-05\n",
      "Epoch 366/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.1050e-05 - val_loss: 5.8644e-05\n",
      "Epoch 367/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9306e-05 - val_loss: 5.5371e-05\n",
      "Epoch 368/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.1189e-05 - val_loss: 5.4831e-05\n",
      "Epoch 369/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9687e-05 - val_loss: 5.4455e-05\n",
      "Epoch 370/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9500e-05 - val_loss: 5.6161e-05\n",
      "Epoch 371/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.0937e-05 - val_loss: 7.6498e-05\n",
      "Epoch 372/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.2382e-05 - val_loss: 5.4034e-05\n",
      "Epoch 373/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.1243e-05 - val_loss: 5.4593e-05\n",
      "Epoch 374/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9674e-05 - val_loss: 5.4694e-05\n",
      "Epoch 375/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.8809e-05 - val_loss: 5.7526e-05\n",
      "Epoch 376/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.9995e-05 - val_loss: 5.4047e-05\n",
      "Epoch 377/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0189e-05 - val_loss: 5.8190e-05\n",
      "Epoch 378/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9751e-05 - val_loss: 5.7645e-05\n",
      "Epoch 379/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0263e-05 - val_loss: 5.5978e-05\n",
      "Epoch 380/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0274e-05 - val_loss: 5.5306e-05\n",
      "Epoch 381/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0748e-05 - val_loss: 5.3747e-05\n",
      "Epoch 382/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0192e-05 - val_loss: 5.3986e-05\n",
      "Epoch 383/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8613e-05 - val_loss: 5.7480e-05\n",
      "Epoch 384/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.1214e-05 - val_loss: 7.2964e-05\n",
      "Epoch 385/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.2530e-05 - val_loss: 5.4150e-05\n",
      "Epoch 386/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9095e-05 - val_loss: 5.3961e-05\n",
      "Epoch 387/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8276e-05 - val_loss: 5.6385e-05\n",
      "Epoch 388/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.1235e-05 - val_loss: 5.4424e-05\n",
      "Epoch 389/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8943e-05 - val_loss: 5.5232e-05\n",
      "Epoch 390/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9232e-05 - val_loss: 6.0230e-05\n",
      "Epoch 391/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.1226e-05 - val_loss: 5.6302e-05\n",
      "Epoch 392/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9361e-05 - val_loss: 5.6812e-05\n",
      "Epoch 393/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.1726e-05 - val_loss: 5.3788e-05\n",
      "Epoch 394/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9191e-05 - val_loss: 5.3966e-05\n",
      "Epoch 395/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8746e-05 - val_loss: 5.5913e-05\n",
      "Epoch 396/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.2649e-05 - val_loss: 7.4077e-05\n",
      "Epoch 397/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.1670e-05 - val_loss: 5.4019e-05\n",
      "Epoch 398/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.0809e-05 - val_loss: 5.3730e-05\n",
      "Epoch 399/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.1727e-05 - val_loss: 5.8780e-05\n",
      "Epoch 400/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.0571e-05 - val_loss: 5.8289e-05\n",
      "Epoch 401/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.4915e-05 - val_loss: 7.0444e-05\n",
      "Epoch 402/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.0219e-05 - val_loss: 5.4622e-05\n",
      "Epoch 403/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9517e-05 - val_loss: 7.8115e-05\n",
      "Epoch 404/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2216e-05 - val_loss: 5.5051e-05\n",
      "Epoch 405/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9197e-05 - val_loss: 5.5322e-05\n",
      "Epoch 406/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9349e-05 - val_loss: 5.4527e-05\n",
      "Epoch 407/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.2150e-05 - val_loss: 5.7409e-05\n",
      "Epoch 408/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9255e-05 - val_loss: 5.4494e-05\n",
      "Epoch 409/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.9898e-05 - val_loss: 7.6017e-05\n",
      "Epoch 410/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.5930e-05 - val_loss: 6.2180e-05\n",
      "Epoch 411/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.9096e-05 - val_loss: 5.7032e-05\n",
      "Epoch 412/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.8813e-05 - val_loss: 5.5263e-05\n",
      "Epoch 413/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8031e-05 - val_loss: 5.8265e-05\n",
      "Epoch 414/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.8058e-05 - val_loss: 6.8102e-05\n",
      "Epoch 415/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9943e-05 - val_loss: 5.4242e-05\n",
      "Epoch 416/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.3504e-05 - val_loss: 8.9753e-05\n",
      "Epoch 417/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9725e-05 - val_loss: 5.4777e-05\n",
      "Epoch 418/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9920e-05 - val_loss: 5.8146e-05\n",
      "Epoch 419/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0410e-05 - val_loss: 5.4319e-05\n",
      "Epoch 420/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9375e-05 - val_loss: 5.5099e-05\n",
      "Epoch 421/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8056e-05 - val_loss: 5.5758e-05\n",
      "Epoch 422/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8697e-05 - val_loss: 5.8443e-05\n",
      "Epoch 423/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9920e-05 - val_loss: 5.6851e-05\n",
      "Epoch 424/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.8488e-05 - val_loss: 5.7236e-05\n",
      "Epoch 425/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9866e-05 - val_loss: 5.3176e-05\n",
      "Epoch 426/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7834e-05 - val_loss: 1.2684e-04\n",
      "Epoch 427/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 5.2540e-05 - val_loss: 6.0223e-05\n",
      "Epoch 428/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7925e-05 - val_loss: 5.7246e-05\n",
      "Epoch 429/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.4458e-05 - val_loss: 5.4793e-05\n",
      "Epoch 430/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8275e-05 - val_loss: 5.2243e-05\n",
      "Epoch 431/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.7795e-05 - val_loss: 5.3005e-05\n",
      "Epoch 432/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8117e-05 - val_loss: 5.5193e-05\n",
      "Epoch 433/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.9646e-05 - val_loss: 6.6393e-05\n",
      "Epoch 434/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7518e-05 - val_loss: 5.5490e-05\n",
      "Epoch 435/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.9017e-05 - val_loss: 5.4876e-05\n",
      "Epoch 436/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.7533e-05 - val_loss: 5.4959e-05\n",
      "Epoch 437/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.9101e-05 - val_loss: 5.3767e-05\n",
      "Epoch 438/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.9133e-05 - val_loss: 5.5767e-05\n",
      "Epoch 439/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7460e-05 - val_loss: 5.7916e-05\n",
      "Epoch 440/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.9884e-05 - val_loss: 5.4796e-05\n",
      "Epoch 441/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7681e-05 - val_loss: 5.6119e-05\n",
      "Epoch 442/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.6905e-05 - val_loss: 5.7188e-05\n",
      "Epoch 443/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7122e-05 - val_loss: 5.7007e-05\n",
      "Epoch 444/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9003e-05 - val_loss: 5.2708e-05\n",
      "Epoch 445/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.9731e-05 - val_loss: 6.3818e-05\n",
      "Epoch 446/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.2239e-05 - val_loss: 5.7926e-05\n",
      "Epoch 447/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9555e-05 - val_loss: 6.7237e-05\n",
      "Epoch 448/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 5.0660e-05 - val_loss: 5.7186e-05\n",
      "Epoch 449/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9726e-05 - val_loss: 6.5234e-05\n",
      "Epoch 450/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 5.0065e-05 - val_loss: 5.5010e-05\n",
      "Epoch 451/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8388e-05 - val_loss: 6.4290e-05\n",
      "Epoch 452/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.8846e-05 - val_loss: 5.8740e-05\n",
      "Epoch 453/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 31ms/step - loss: 5.0232e-05 - val_loss: 6.3883e-05\n",
      "Epoch 454/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 5.4888e-05 - val_loss: 5.5554e-05\n",
      "Epoch 455/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8944e-05 - val_loss: 5.9297e-05\n",
      "Epoch 456/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.8548e-05 - val_loss: 5.4341e-05\n",
      "Epoch 457/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.7419e-05 - val_loss: 5.5802e-05\n",
      "Epoch 458/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.8326e-05 - val_loss: 7.1022e-05\n",
      "Epoch 459/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.8646e-05 - val_loss: 5.5248e-05\n",
      "Epoch 460/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9559e-05 - val_loss: 5.2654e-05\n",
      "Epoch 461/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.7177e-05 - val_loss: 5.2218e-05\n",
      "Epoch 462/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6833e-05 - val_loss: 5.5129e-05\n",
      "Epoch 463/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6529e-05 - val_loss: 5.2221e-05\n",
      "Epoch 464/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 31ms/step - loss: 5.1027e-05 - val_loss: 5.8197e-05\n",
      "Epoch 465/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.7161e-05 - val_loss: 5.3254e-05\n",
      "Epoch 466/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6970e-05 - val_loss: 5.4317e-05\n",
      "Epoch 467/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.7889e-05 - val_loss: 5.2640e-05\n",
      "Epoch 468/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6804e-05 - val_loss: 5.2004e-05\n",
      "Epoch 469/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.7495e-05 - val_loss: 6.4880e-05\n",
      "Epoch 470/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.9994e-05 - val_loss: 5.2188e-05\n",
      "Epoch 471/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6361e-05 - val_loss: 5.3188e-05\n",
      "Epoch 472/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.7309e-05 - val_loss: 5.1202e-05\n",
      "Epoch 473/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.7979e-05 - val_loss: 5.8838e-05\n",
      "Epoch 474/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.6606e-05 - val_loss: 6.2898e-05\n",
      "Epoch 475/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 31ms/step - loss: 4.6698e-05 - val_loss: 5.7397e-05\n",
      "Epoch 476/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.6362e-05 - val_loss: 5.6053e-05\n",
      "Epoch 477/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.6668e-05 - val_loss: 5.2272e-05\n",
      "Epoch 478/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.6630e-05 - val_loss: 5.2228e-05\n",
      "Epoch 479/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.8749e-05 - val_loss: 5.2564e-05\n",
      "Epoch 480/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6186e-05 - val_loss: 5.5811e-05\n",
      "Epoch 481/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7543e-05 - val_loss: 5.6441e-05\n",
      "Epoch 482/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 31ms/step - loss: 4.5882e-05 - val_loss: 5.7687e-05\n",
      "Epoch 483/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6138e-05 - val_loss: 6.1743e-05\n",
      "Epoch 484/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7795e-05 - val_loss: 5.1787e-05\n",
      "Epoch 485/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.7374e-05 - val_loss: 5.4489e-05\n",
      "Epoch 486/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.6505e-05 - val_loss: 5.5259e-05\n",
      "Epoch 487/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.6798e-05 - val_loss: 5.6518e-05\n",
      "Epoch 488/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.6223e-05 - val_loss: 5.5075e-05\n",
      "Epoch 489/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.7915e-05 - val_loss: 5.1619e-05\n",
      "Epoch 490/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 31ms/step - loss: 4.8166e-05 - val_loss: 5.1956e-05\n",
      "Epoch 491/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6045e-05 - val_loss: 5.4927e-05\n",
      "Epoch 492/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.5657e-05 - val_loss: 5.2513e-05\n",
      "Epoch 493/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.8661e-05 - val_loss: 5.1383e-05\n",
      "Epoch 494/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7890e-05 - val_loss: 5.0867e-05\n",
      "Epoch 495/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5328e-05 - val_loss: 5.4135e-05\n",
      "Epoch 496/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.8709e-05 - val_loss: 7.3383e-05\n",
      "Epoch 497/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7958e-05 - val_loss: 5.0362e-05\n",
      "Epoch 498/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5961e-05 - val_loss: 5.0886e-05\n",
      "Epoch 499/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7586e-05 - val_loss: 5.0836e-05\n",
      "Epoch 500/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5865e-05 - val_loss: 5.9456e-05\n",
      "Epoch 501/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7517e-05 - val_loss: 5.2449e-05\n",
      "Epoch 502/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5799e-05 - val_loss: 5.1718e-05\n",
      "Epoch 503/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6148e-05 - val_loss: 6.5277e-05\n",
      "Epoch 504/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 4.9059e-05 - val_loss: 6.3515e-05\n",
      "Epoch 505/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.8284e-05 - val_loss: 5.4000e-05\n",
      "Epoch 506/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.6590e-05 - val_loss: 5.1167e-05\n",
      "Epoch 507/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 4.6642e-05 - val_loss: 5.4529e-05\n",
      "Epoch 508/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6427e-05 - val_loss: 5.0744e-05\n",
      "Epoch 509/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5796e-05 - val_loss: 5.0474e-05\n",
      "Epoch 510/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.7720e-05 - val_loss: 6.7228e-05\n",
      "Epoch 511/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.6268e-05 - val_loss: 5.0845e-05\n",
      "Epoch 512/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6064e-05 - val_loss: 5.2028e-05\n",
      "Epoch 513/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6574e-05 - val_loss: 5.1527e-05\n",
      "Epoch 514/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6023e-05 - val_loss: 5.0718e-05\n",
      "Epoch 515/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6371e-05 - val_loss: 5.1284e-05\n",
      "Epoch 516/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.6877e-05 - val_loss: 5.0624e-05\n",
      "Epoch 517/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.5751e-05 - val_loss: 5.1346e-05\n",
      "Epoch 518/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5377e-05 - val_loss: 5.1528e-05\n",
      "Epoch 519/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.7725e-05 - val_loss: 6.7700e-05\n",
      "Epoch 520/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6195e-05 - val_loss: 5.1264e-05\n",
      "Epoch 521/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6325e-05 - val_loss: 6.1954e-05\n",
      "Epoch 522/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 4.7103e-05 - val_loss: 5.3344e-05\n",
      "Epoch 523/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5485e-05 - val_loss: 6.9171e-05\n",
      "Epoch 524/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6327e-05 - val_loss: 5.1389e-05\n",
      "Epoch 525/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6236e-05 - val_loss: 5.0787e-05\n",
      "Epoch 526/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.7122e-05 - val_loss: 5.1191e-05\n",
      "Epoch 527/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 4.5747e-05 - val_loss: 5.7128e-05\n",
      "Epoch 528/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 4.5397e-05 - val_loss: 5.1933e-05\n",
      "Epoch 529/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.8183e-05 - val_loss: 5.4632e-05\n",
      "Epoch 530/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 32ms/step - loss: 4.5860e-05 - val_loss: 5.2592e-05\n",
      "Epoch 531/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6166e-05 - val_loss: 5.1229e-05\n",
      "Epoch 532/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6265e-05 - val_loss: 5.0795e-05\n",
      "Epoch 533/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 4.6211e-05 - val_loss: 5.1628e-05\n",
      "Epoch 534/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6910e-05 - val_loss: 5.8189e-05\n",
      "Epoch 535/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5849e-05 - val_loss: 5.3550e-05\n",
      "Epoch 536/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5245e-05 - val_loss: 5.0942e-05\n",
      "Epoch 537/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5517e-05 - val_loss: 5.1825e-05\n",
      "Epoch 538/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5185e-05 - val_loss: 5.2514e-05\n",
      "Epoch 539/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5452e-05 - val_loss: 6.8780e-05\n",
      "Epoch 540/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.8009e-05 - val_loss: 5.3842e-05\n",
      "Epoch 541/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6763e-05 - val_loss: 5.3384e-05\n",
      "Epoch 542/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 4.5374e-05 - val_loss: 5.2896e-05\n",
      "Epoch 543/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6969e-05 - val_loss: 7.1700e-05\n",
      "Epoch 544/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.6466e-05 - val_loss: 5.2944e-05\n",
      "Epoch 545/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5762e-05 - val_loss: 5.2329e-05\n",
      "Epoch 546/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5281e-05 - val_loss: 5.5848e-05\n",
      "Epoch 547/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 33ms/step - loss: 4.5356e-05 - val_loss: 6.3146e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### # Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model and get the training history with early stopping\n",
    "history = hybrid_sr_model.fit(\n",
    "    X_train_lr, \n",
    "    X_train_hr, \n",
    "    epochs=1000, \n",
    "    batch_size=4, \n",
    "    validation_data=(X_validation_lr, X_validation_hr),\n",
    "    callbacks=[early_stopping]  # Add the early stopping callback here\n",
    ")\n",
    "\n",
    "# Visualize training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee40a9b",
   "metadata": {},
   "source": [
    "## Compute all the metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87cb51f-9703-448a-bc7e-cc5e152d396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 16:59:13.911294: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,32,72,72]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,72,72]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-07 16:59:14.270761: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,144,144]{3,2,1,0}, f32[6,64,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 16:59:19.883717: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[23,32,72,72]{3,2,1,0}, u8[0]{0}) custom-call(f32[23,32,72,72]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-07 16:59:20.225774: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[23,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[23,64,144,144]{3,2,1,0}, f32[6,64,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step\n",
      "Average PSNR on the test set: 38.204044946637744\n",
      "Average SSIM on the test set: 0.9653219\n",
      "Average SAM on the test set (in degrees): 1.4591410626346006\n",
      "Average Correlation Coefficient on the test set: 0.991946185170591\n",
      "Average ERGAS on the test set: 1.807756324491408\n",
      "Average RMSE: 0.012954918\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate PSNR without normalization\n",
    "def psnr(y_true, y_pred):\n",
    "    max_pixel = np.max(y_true)  # Use the actual max value from y_true\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    if mse == 0:  # Avoid log of zero\n",
    "        return float('inf')\n",
    "    psnr_value = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    return psnr_value\n",
    "\n",
    "# Function to calculate SSIM with channel_axis\n",
    "def ssim_value(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Shape mismatch: y_true shape {y_true.shape} vs y_pred shape {y_pred.shape}\")\n",
    "    \n",
    "    data_range = y_true.max() - y_true.min()  # Calculate data range from y_true\n",
    "    ssim_val = ssim(y_true, y_pred, data_range=data_range, channel_axis=-1)\n",
    "    return ssim_val\n",
    "\n",
    "# Function to calculate Correlation Coefficient\n",
    "def correlation_coefficient(y_true, y_pred):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    corr_matrix = np.corrcoef(y_true_flat, y_pred_flat)\n",
    "    corr_value = corr_matrix[0, 1]\n",
    "    return corr_value\n",
    "\n",
    "# Function to calculate Spectral Angle Mapper (SAM) in degrees\n",
    "def sam(y_true, y_pred):\n",
    "    y_true_reshaped = y_true.reshape(-1, y_true.shape[-1])\n",
    "    y_pred_reshaped = y_pred.reshape(-1, y_pred.shape[-1])\n",
    "    \n",
    "    non_zero_mask = (np.linalg.norm(y_true_reshaped, axis=1) > 1e-10) & (np.linalg.norm(y_pred_reshaped, axis=1) > 1e-10)\n",
    "    dot_product = np.sum(y_true_reshaped[non_zero_mask] * y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    norm_true = np.linalg.norm(y_true_reshaped[non_zero_mask], axis=1)\n",
    "    norm_pred = np.linalg.norm(y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        angles = np.arccos(np.clip(dot_product / (norm_true * norm_pred), -1.0, 1.0))\n",
    "    \n",
    "    if angles.size > 0:\n",
    "        sam_value_degrees = np.mean(angles) * (180 / np.pi)\n",
    "    else:\n",
    "        sam_value_degrees = 0\n",
    "    \n",
    "    return sam_value_degrees\n",
    "\n",
    "# Function to normalize the images\n",
    "def normalize(image):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    return (image - min_val) / (max_val - min_val)  # Normalize to [0, 1]\n",
    "\n",
    "# Function to calculate Root Mean Squared Error (RMSE) for hyperspectral images (normalized)\n",
    "def rmse_bandwise(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\"Shape mismatch between true and predicted images.\")\n",
    "    \n",
    "    bands = y_true.shape[-1]\n",
    "    rmse_per_band = []\n",
    "\n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        \n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)\n",
    "        rmse_band_value = np.sqrt(mse_band)\n",
    "        rmse_per_band.append(rmse_band_value)\n",
    "\n",
    "    # Normalize RMSE by the maximum value in y_true across all bands\n",
    "    max_value = np.max(y_true)\n",
    "    normalized_rmse = np.mean(rmse_per_band) / max_value\n",
    "    return normalized_rmse\n",
    "\n",
    "# Function to calculate ERGAS\n",
    "def ergas(y_true, y_pred, scale):\n",
    "    bands = y_true.shape[-1]\n",
    "    ergas_value = 0\n",
    "    \n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        mean_band_true = np.mean(band_true)\n",
    "        \n",
    "        # Calculate RMSE for the band without using a separate function\n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)  # Mean Squared Error for the band\n",
    "        rmse_band = np.sqrt(mse_band)  # Root Mean Squared Error for the band\n",
    "        \n",
    "        ergas_value += (rmse_band / mean_band_true) ** 2\n",
    "    \n",
    "    ergas_value = 100 * (1 / scale) * np.sqrt(ergas_value / bands)\n",
    "    return ergas_value\n",
    "\n",
    "# Assuming hybrid_sr_model is trained, and X_test_lr, X_test_hr are defined\n",
    "predicted_hr_images = hybrid_sr_model.predict(X_test_lr)\n",
    "downscale_factor = 4  # ERGAS downscale factor\n",
    "\n",
    "# Validate shapes match for test and predictions\n",
    "if predicted_hr_images.shape != X_test_hr.shape:\n",
    "    raise ValueError(f\"Shape mismatch: predicted_hr_images shape {predicted_hr_images.shape} vs X_test_hr shape {X_test_hr.shape}\")\n",
    "\n",
    "# Calculate metrics per test sample\n",
    "psnr_values, ssim_values, cc_values, sam_values, ergas_values, rmse_values = [], [], [], [], [], []\n",
    "\n",
    "for i in range(len(X_test_hr)):\n",
    "    psnr_values.append(psnr(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ssim_values.append(ssim_value(X_test_hr[i], predicted_hr_images[i]))\n",
    "    cc_values.append(correlation_coefficient(X_test_hr[i], predicted_hr_images[i]))\n",
    "    sam_values.append(sam(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ergas_values.append(ergas(X_test_hr[i], predicted_hr_images[i], downscale_factor))\n",
    "    rmse_values.append(rmse_bandwise(X_test_hr[i], predicted_hr_images[i]))\n",
    "\n",
    "# Average metrics\n",
    "average_psnr = np.mean(psnr_values)\n",
    "average_ssim = np.mean(ssim_values)\n",
    "average_cc = np.mean(cc_values)\n",
    "average_sam = np.mean(sam_values)\n",
    "average_ergas = np.mean(ergas_values)\n",
    "average_rmse = np.mean(rmse_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Average PSNR on the test set:\", average_psnr)\n",
    "print(\"Average SSIM on the test set:\", average_ssim)\n",
    "print(\"Average SAM on the test set (in degrees):\", average_sam)\n",
    "print(\"Average Correlation Coefficient on the test set:\", average_cc)\n",
    "print(\"Average ERGAS on the test set:\", average_ergas)\n",
    "print(\"Average RMSE:\", average_rmse)  # Indicate RMSE is normalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52963864",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from spectral import open_image\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, Activation, Add, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a88919",
   "metadata": {},
   "source": [
    "## Preprocess dataset with band grouping for scaling 4x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3da9f5-77c9-49a9-8088-2fc05d01b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741287130.160229  931246 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_hr shape: (5902, 144, 144, 6)\n",
      "X_validation_hr shape: (843, 144, 144, 6)\n",
      "X_test_hr shape: (1687, 144, 144, 6)\n",
      "X_train_lr shape: (5902, 36, 36, 6)\n",
      "X_validation_lr shape: (843, 36, 36, 6)\n",
      "X_test_lr shape: (1687, 36, 36, 6)\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the path to the hyperspectral data\n",
    "header_file = \"HyperspecVNIR_Chikusei_20140729.hdr\"\n",
    "\n",
    "# Load the hyperspectral data\n",
    "img = open_image(header_file)\n",
    "data = img.load()\n",
    "\n",
    "# Parameters\n",
    "patch_size = (144, 144)  # Size of patches to extract\n",
    "test_size = 0.2  # Proportion of data for testing\n",
    "validation_size = 0.1  # Proportion of data for validation\n",
    "downscale_factor = 4  # Factor to downscale patches\n",
    "nodata_value = 15000.0  # Value that indicates \"no data\"\n",
    "group_size = 6  # Group size for spectral bands\n",
    "overlap_size = 2  # Overlap size for grouped bands\n",
    "\n",
    "# Function to group bands into overlapping subgroups\n",
    "def group_bands_with_overlap(data, group_size=6, overlap_size=2):\n",
    "    height, width, bands = data.shape\n",
    "    step_size = group_size - overlap_size  # Calculate step size based on overlap\n",
    "    grouped_data = []\n",
    "\n",
    "    # Create overlapping groups of bands\n",
    "    for g in range(0, bands - group_size + 1, step_size):\n",
    "        group = data[:, :, g:g + group_size]\n",
    "        grouped_data.append(group)\n",
    "    \n",
    "    return np.array(grouped_data)\n",
    "\n",
    "# Function to extract and downscale patches from hyperspectral data\n",
    "def extract_and_downscale_patches(data, patch_size, downscale_factor, nodata_value=0):\n",
    "    patches_hr = []\n",
    "    patches_lr = []\n",
    "    height, width, bands = data.shape\n",
    "\n",
    "    for i in range(0, height - patch_size[0] + 1, patch_size[0]):\n",
    "        for j in range(0, width - patch_size[1] + 1, patch_size[1]):\n",
    "            patch_hr = data[i:i + patch_size[0], j:j + patch_size[1], :]\n",
    "\n",
    "            # Check for nodata_value and skip patch extraction if present\n",
    "            if np.any(patch_hr == nodata_value):\n",
    "                continue\n",
    "            \n",
    "            patch_lr = tf.image.resize(patch_hr, \n",
    "                                       [patch_size[0] // downscale_factor, patch_size[1] // downscale_factor], \n",
    "                                       method='bilinear')\n",
    "            patches_hr.append(patch_hr)\n",
    "            patches_lr.append(patch_lr.numpy())  # Convert tensor to numpy\n",
    "\n",
    "    return np.array(patches_hr), np.array(patches_lr)\n",
    "\n",
    "# Group bands into overlapping subgroups\n",
    "grouped_data = group_bands_with_overlap(data, group_size=group_size, overlap_size=overlap_size)\n",
    "\n",
    "# Extract and downscale patches for all groups\n",
    "all_patches_hr = []\n",
    "all_patches_lr = []\n",
    "\n",
    "for group in grouped_data:\n",
    "    patches_hr, patches_lr = extract_and_downscale_patches(group, patch_size, downscale_factor, nodata_value=nodata_value)\n",
    "    all_patches_hr.append(patches_hr)\n",
    "    all_patches_lr.append(patches_lr)\n",
    "\n",
    "# Concatenate patches from all groups\n",
    "all_patches_hr = np.concatenate(all_patches_hr, axis=0)\n",
    "all_patches_lr = np.concatenate(all_patches_lr, axis=0)\n",
    "\n",
    "# Calculate the number of patches\n",
    "num_patches = len(all_patches_hr)\n",
    "\n",
    "# Calculate sizes for training, validation, and testing sets\n",
    "train_size = int((1 - test_size - validation_size) * num_patches)\n",
    "validation_size = int(validation_size * num_patches)\n",
    "test_size = num_patches - (train_size + validation_size)  # Explicit calculation of test size\n",
    "\n",
    "# Shuffle indices for splitting the data\n",
    "indices = np.arange(num_patches)\n",
    "np.random.shuffle(indices)\n",
    "all_patches_hr = all_patches_hr[indices]\n",
    "all_patches_lr = all_patches_lr[indices]\n",
    "\n",
    "# Split into training, validation, and testing sets\n",
    "X_train_hr, X_validation_hr, X_test_hr = np.split(all_patches_hr, [train_size, train_size + validation_size])\n",
    "X_train_lr, X_validation_lr, X_test_lr = np.split(all_patches_lr, [train_size, train_size + validation_size])\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"X_train_hr shape:\", X_train_hr.shape)\n",
    "print(\"X_validation_hr shape:\", X_validation_hr.shape)\n",
    "print(\"X_test_hr shape:\", X_test_hr.shape)\n",
    "\n",
    "print(\"X_train_lr shape:\", X_train_lr.shape)\n",
    "print(\"X_validation_lr shape:\", X_validation_lr.shape)\n",
    "print(\"X_test_lr shape:\", X_test_lr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99aa47",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9afece-281b-46c2-896c-1b7165765280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Spatial–Spectral Gradient Loss Function\n",
    "def spatial_spectral_gradient_loss(y_true, y_pred):\n",
    "    mse_loss = K.mean(K.square(y_true - y_pred))\n",
    "    \n",
    "    def spatial_gradient_loss(y_true, y_pred):\n",
    "        grad_y_true_x = y_true[:, :, 1:, :] - y_true[:, :, :-1, :]\n",
    "        grad_y_pred_x = y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :]\n",
    "        grad_y_true_y = y_true[:, 1:, :, :] - y_true[:, :-1, :, :]\n",
    "        grad_y_pred_y = y_pred[:, 1:, :, :] - y_pred[:, :-1, :, :]\n",
    "        \n",
    "        loss_x = K.mean(K.square(grad_y_true_x - grad_y_pred_x))\n",
    "        loss_y = K.mean(K.square(grad_y_true_y - grad_y_pred_y))\n",
    "        \n",
    "        return loss_x + loss_y\n",
    "\n",
    "    def spectral_gradient_loss(y_true, y_pred):\n",
    "        grad_y_true_spectral = y_true[:, :, :, 1:] - y_true[:, :, :, :-1]\n",
    "        grad_y_pred_spectral = y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1]\n",
    "        return K.mean(K.square(grad_y_true_spectral - grad_y_pred_spectral))\n",
    "\n",
    "    spatial_loss = spatial_gradient_loss(y_true, y_pred)\n",
    "    spectral_loss = spectral_gradient_loss(y_true, y_pred)\n",
    "    \n",
    "    total_loss = mse_loss + 0.1 * spatial_loss + 0.1 * spectral_loss\n",
    "    return total_loss\n",
    "\n",
    "# Residual Block\n",
    "def residual_block(x, filters=32):\n",
    "    res = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    res = BatchNormalization()(res)\n",
    "    res = Activation('relu')(res)\n",
    "    res = Conv2D(filters, (3, 3), padding='same')(res)\n",
    "    res = BatchNormalization()(res)\n",
    "    return Add()([x, res])\n",
    "\n",
    "# Spectral–Spatial Block\n",
    "def spectral_spatial_block(x, filters=32):\n",
    "    spatial = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    spatial = BatchNormalization()(spatial)\n",
    "    spatial = Activation('relu')(spatial)\n",
    "    \n",
    "    spectral = Conv2D(filters, (1, 1), padding='same')(x)\n",
    "    spectral = BatchNormalization()(spectral)\n",
    "    spectral = Activation('relu')(spectral)\n",
    "    \n",
    "    spatial = Conv2D(filters, (1, 1), padding='same')(spatial)\n",
    "    \n",
    "    combined = Concatenate(axis=-1)([spatial, spectral])\n",
    "    return combined\n",
    "\n",
    "# Spectral Unmixing Block\n",
    "def spectral_unmixing_block(x, num_endmembers=40):\n",
    "    x = Conv2D(num_endmembers, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    return x\n",
    "\n",
    "# Upsampling Block \n",
    "def upsample_block(x, filters, scale=2, use_transpose=True):\n",
    "    if use_transpose:\n",
    "        x = Conv2DTranspose(filters, (3, 3), strides=(scale, scale), padding='same')(x)\n",
    "    else:\n",
    "        x = UpSampling2D(size=(scale, scale))(x)\n",
    "        x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Build Model with Configurable Upsampling\n",
    "def build_hybrid_sr_model(input_shape, num_endmembers=40, use_transpose=True):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(32, (9, 9), padding='same')(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    for _ in range(50):\n",
    "        x = residual_block(x)\n",
    "    \n",
    "    x = spectral_spatial_block(x)\n",
    "    \n",
    "    x_unmixed = spectral_unmixing_block(x, num_endmembers)\n",
    "    \n",
    "    x_concat = Concatenate(axis=-1)([x, x_unmixed])\n",
    "    \n",
    "    x_up = upsample_block(x_concat, filters=64, scale=2, use_transpose=use_transpose)  # 2x upscaling\n",
    "    x_up = upsample_block(x_up, filters=32, scale=2, use_transpose=use_transpose)  # 4x upscaling\n",
    "    \n",
    "    x_out = Conv2D(input_shape[-1], (3, 3), padding='same')(x_up)\n",
    "    x_out = Activation('linear')(x_out)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x_out)\n",
    "    return model\n",
    "\n",
    "# Define input shape and build model\n",
    "input_shape = (36, 36, 6)\n",
    "num_endmembers = 40\n",
    "use_transpose = True  \n",
    "\n",
    "hybrid_sr_model = build_hybrid_sr_model(input_shape, num_endmembers=num_endmembers, use_transpose=use_transpose)\n",
    "\n",
    "# Compile the model with the custom loss function\n",
    "hybrid_sr_model.compile(optimizer='adam', loss=spatial_spectral_gradient_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea40d8ea",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531448ae-e872-4b62-a802-e1754e3049cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741287196.170531  931346 service.cc:148] XLA service 0x7f24d4001980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741287196.171391  931346 service.cc:156]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2025-03-06 20:53:17.770863: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741287203.224583  931346 cuda_dnn.cc:529] Loaded cuDNN version 90501\n",
      "2025-03-06 20:53:29.472194: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,32,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,32,36,36]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-06 20:53:29.964033: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,32,144,144]{3,2,1,0}, f32[6,32,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   3/1476\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 26ms/step - loss: 1.2803    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741287223.395035  931346 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1473/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 20:54:24.769331: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[2,32,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,32,36,36]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-06 20:54:24.895028: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[2,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[2,32,144,144]{3,2,1,0}, f32[6,32,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 20:54:43.238397: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[3,32,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,32,36,36]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-06 20:54:43.353936: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[3,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,32,144,144]{3,2,1,0}, f32[6,32,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 41ms/step - loss: 0.0287 - val_loss: 0.0020\n",
      "Epoch 2/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 3/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 4/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 9.5334e-04\n",
      "Epoch 5/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 9.0915e-04\n",
      "Epoch 6/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 9.4258e-04 - val_loss: 7.9432e-04\n",
      "Epoch 8/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 8.5968e-04 - val_loss: 7.0839e-04\n",
      "Epoch 9/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 8.3530e-04 - val_loss: 6.8827e-04\n",
      "Epoch 10/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 7.9018e-04 - val_loss: 6.6604e-04\n",
      "Epoch 11/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 7.6430e-04 - val_loss: 6.0151e-04\n",
      "Epoch 12/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 6.8990e-04 - val_loss: 5.8449e-04\n",
      "Epoch 13/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 6.5662e-04 - val_loss: 5.7533e-04\n",
      "Epoch 14/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 6.4161e-04 - val_loss: 5.5767e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 6.2198e-04 - val_loss: 5.4042e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 6.0272e-04 - val_loss: 5.2485e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 5.8850e-04 - val_loss: 5.1856e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 5.6821e-04 - val_loss: 5.3569e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 5.6243e-04 - val_loss: 5.0255e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 5.4307e-04 - val_loss: 5.2307e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 5.3604e-04 - val_loss: 4.9039e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 5.1732e-04 - val_loss: 4.9678e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 4.9924e-04 - val_loss: 5.0404e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 5.0332e-04 - val_loss: 4.4812e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 25ms/step - loss: 4.7058e-04 - val_loss: 4.4025e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 26ms/step - loss: 4.5327e-04 - val_loss: 4.6428e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 4.7441e-04 - val_loss: 4.3184e-04\n",
      "Epoch 28/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 4.3953e-04 - val_loss: 4.1430e-04\n",
      "Epoch 29/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 4.2883e-04 - val_loss: 4.3861e-04\n",
      "Epoch 30/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 4.1726e-04 - val_loss: 4.3975e-04\n",
      "Epoch 31/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 4.1608e-04 - val_loss: 4.0382e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 4.0201e-04 - val_loss: 3.9406e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.9009e-04 - val_loss: 4.0250e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.8434e-04 - val_loss: 3.9293e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.7506e-04 - val_loss: 3.6963e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 3.6635e-04 - val_loss: 3.8404e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.6586e-04 - val_loss: 3.6469e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.6080e-04 - val_loss: 3.6892e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.5206e-04 - val_loss: 3.6034e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 3.4568e-04 - val_loss: 3.5427e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.3912e-04 - val_loss: 3.9689e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.5315e-04 - val_loss: 3.5626e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 3.3295e-04 - val_loss: 3.6715e-04\n",
      "Epoch 44/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.2892e-04 - val_loss: 3.2271e-04\n",
      "Epoch 45/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.2505e-04 - val_loss: 3.1958e-04\n",
      "Epoch 46/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.1581e-04 - val_loss: 3.2222e-04\n",
      "Epoch 47/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.1756e-04 - val_loss: 3.3346e-04\n",
      "Epoch 48/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.1316e-04 - val_loss: 3.2194e-04\n",
      "Epoch 49/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.0433e-04 - val_loss: 3.1730e-04\n",
      "Epoch 50/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.0484e-04 - val_loss: 3.2616e-04\n",
      "Epoch 51/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.0664e-04 - val_loss: 4.1421e-04\n",
      "Epoch 52/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.1122e-04 - val_loss: 3.4824e-04\n",
      "Epoch 53/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 3.0288e-04 - val_loss: 3.5377e-04\n",
      "Epoch 54/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.9485e-04 - val_loss: 3.5989e-04\n",
      "Epoch 55/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.8831e-04 - val_loss: 3.3242e-04\n",
      "Epoch 56/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.8712e-04 - val_loss: 3.2150e-04\n",
      "Epoch 57/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.9040e-04 - val_loss: 3.0378e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.8072e-04 - val_loss: 3.5128e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.7922e-04 - val_loss: 3.0050e-04\n",
      "Epoch 60/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.8337e-04 - val_loss: 3.0557e-04\n",
      "Epoch 61/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.8616e-04 - val_loss: 3.2877e-04\n",
      "Epoch 62/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.7502e-04 - val_loss: 3.2027e-04\n",
      "Epoch 63/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.6731e-04 - val_loss: 3.2037e-04\n",
      "Epoch 64/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 24ms/step - loss: 2.7075e-04 - val_loss: 2.8560e-04\n",
      "Epoch 65/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.7337e-04 - val_loss: 2.9780e-04\n",
      "Epoch 66/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.6573e-04 - val_loss: 3.0275e-04\n",
      "Epoch 67/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.6727e-04 - val_loss: 2.9504e-04\n",
      "Epoch 68/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.6796e-04 - val_loss: 2.7666e-04\n",
      "Epoch 69/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.7355e-04 - val_loss: 2.6988e-04\n",
      "Epoch 70/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.6288e-04 - val_loss: 2.6605e-04\n",
      "Epoch 71/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.6208e-04 - val_loss: 2.7174e-04\n",
      "Epoch 72/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.5778e-04 - val_loss: 2.7366e-04\n",
      "Epoch 73/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.6223e-04 - val_loss: 2.8372e-04\n",
      "Epoch 74/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.6854e-04 - val_loss: 3.0217e-04\n",
      "Epoch 75/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.7026e-04 - val_loss: 2.7256e-04\n",
      "Epoch 76/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.5888e-04 - val_loss: 2.7164e-04\n",
      "Epoch 77/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.5529e-04 - val_loss: 2.7225e-04\n",
      "Epoch 78/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.5119e-04 - val_loss: 2.6217e-04\n",
      "Epoch 79/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.5042e-04 - val_loss: 2.6242e-04\n",
      "Epoch 80/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4865e-04 - val_loss: 2.6324e-04\n",
      "Epoch 81/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4559e-04 - val_loss: 2.5893e-04\n",
      "Epoch 82/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4447e-04 - val_loss: 2.6768e-04\n",
      "Epoch 83/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.5388e-04 - val_loss: 2.6690e-04\n",
      "Epoch 84/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4931e-04 - val_loss: 2.6554e-04\n",
      "Epoch 85/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.5137e-04 - val_loss: 2.6071e-04\n",
      "Epoch 86/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.5441e-04 - val_loss: 2.5251e-04\n",
      "Epoch 87/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4670e-04 - val_loss: 2.5553e-04\n",
      "Epoch 88/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4450e-04 - val_loss: 2.5713e-04\n",
      "Epoch 89/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.6478e-04 - val_loss: 2.6262e-04\n",
      "Epoch 90/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.5444e-04 - val_loss: 2.5760e-04\n",
      "Epoch 91/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4416e-04 - val_loss: 2.4630e-04\n",
      "Epoch 92/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4327e-04 - val_loss: 2.4554e-04\n",
      "Epoch 93/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3849e-04 - val_loss: 2.6295e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4154e-04 - val_loss: 2.4667e-04\n",
      "Epoch 95/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3286e-04 - val_loss: 2.4356e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3231e-04 - val_loss: 2.4315e-04\n",
      "Epoch 97/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3006e-04 - val_loss: 2.4252e-04\n",
      "Epoch 98/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2715e-04 - val_loss: 2.4742e-04\n",
      "Epoch 99/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.3263e-04 - val_loss: 2.9611e-04\n",
      "Epoch 100/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 28ms/step - loss: 2.3719e-04 - val_loss: 2.5183e-04\n",
      "Epoch 101/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3079e-04 - val_loss: 2.4376e-04\n",
      "Epoch 102/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2914e-04 - val_loss: 2.5763e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3223e-04 - val_loss: 2.4885e-04\n",
      "Epoch 104/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3026e-04 - val_loss: 2.3574e-04\n",
      "Epoch 105/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2762e-04 - val_loss: 2.4667e-04\n",
      "Epoch 106/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3119e-04 - val_loss: 2.3995e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2310e-04 - val_loss: 2.3698e-04\n",
      "Epoch 108/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2517e-04 - val_loss: 2.3483e-04\n",
      "Epoch 109/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2197e-04 - val_loss: 2.3555e-04\n",
      "Epoch 110/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2292e-04 - val_loss: 2.3868e-04\n",
      "Epoch 111/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2370e-04 - val_loss: 2.3403e-04\n",
      "Epoch 112/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2549e-04 - val_loss: 2.3685e-04\n",
      "Epoch 113/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2186e-04 - val_loss: 2.3449e-04\n",
      "Epoch 114/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2429e-04 - val_loss: 2.6880e-04\n",
      "Epoch 115/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2988e-04 - val_loss: 2.5970e-04\n",
      "Epoch 116/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3067e-04 - val_loss: 2.4848e-04\n",
      "Epoch 117/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2722e-04 - val_loss: 2.4548e-04\n",
      "Epoch 118/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2405e-04 - val_loss: 2.4293e-04\n",
      "Epoch 119/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2057e-04 - val_loss: 2.4006e-04\n",
      "Epoch 120/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1761e-04 - val_loss: 2.3744e-04\n",
      "Epoch 121/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1744e-04 - val_loss: 2.3737e-04\n",
      "Epoch 122/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2627e-04 - val_loss: 2.3813e-04\n",
      "Epoch 123/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2607e-04 - val_loss: 2.3479e-04\n",
      "Epoch 124/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 24ms/step - loss: 2.3083e-04 - val_loss: 2.3275e-04\n",
      "Epoch 125/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3084e-04 - val_loss: 2.3272e-04\n",
      "Epoch 126/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.2858e-04 - val_loss: 2.4997e-04\n",
      "Epoch 127/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2924e-04 - val_loss: 2.3221e-04\n",
      "Epoch 128/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2572e-04 - val_loss: 2.3393e-04\n",
      "Epoch 129/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2590e-04 - val_loss: 2.3422e-04\n",
      "Epoch 130/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2829e-04 - val_loss: 2.3136e-04\n",
      "Epoch 131/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2536e-04 - val_loss: 2.3091e-04\n",
      "Epoch 132/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.1882e-04 - val_loss: 2.2843e-04\n",
      "Epoch 133/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.1631e-04 - val_loss: 2.2984e-04\n",
      "Epoch 134/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1299e-04 - val_loss: 2.2959e-04\n",
      "Epoch 135/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1496e-04 - val_loss: 2.3803e-04\n",
      "Epoch 136/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.1504e-04 - val_loss: 2.3505e-04\n",
      "Epoch 137/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1414e-04 - val_loss: 2.3576e-04\n",
      "Epoch 138/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2099e-04 - val_loss: 2.2840e-04\n",
      "Epoch 139/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.1789e-04 - val_loss: 2.3191e-04\n",
      "Epoch 140/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1666e-04 - val_loss: 2.2760e-04\n",
      "Epoch 141/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1950e-04 - val_loss: 2.4051e-04\n",
      "Epoch 142/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2095e-04 - val_loss: 2.4414e-04\n",
      "Epoch 143/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.4249e-04 - val_loss: 2.6188e-04\n",
      "Epoch 144/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.1674e-04 - val_loss: 2.3176e-04\n",
      "Epoch 145/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0888e-04 - val_loss: 2.3936e-04\n",
      "Epoch 146/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.0950e-04 - val_loss: 2.3937e-04\n",
      "Epoch 147/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1283e-04 - val_loss: 2.3062e-04\n",
      "Epoch 148/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 24ms/step - loss: 2.1093e-04 - val_loss: 2.7007e-04\n",
      "Epoch 149/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.1700e-04 - val_loss: 2.2482e-04\n",
      "Epoch 150/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1510e-04 - val_loss: 2.3772e-04\n",
      "Epoch 151/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1209e-04 - val_loss: 2.3285e-04\n",
      "Epoch 152/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1330e-04 - val_loss: 2.2688e-04\n",
      "Epoch 153/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1556e-04 - val_loss: 2.3516e-04\n",
      "Epoch 154/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1925e-04 - val_loss: 2.6845e-04\n",
      "Epoch 155/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2479e-04 - val_loss: 2.3314e-04\n",
      "Epoch 156/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2074e-04 - val_loss: 2.2965e-04\n",
      "Epoch 157/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1344e-04 - val_loss: 2.2493e-04\n",
      "Epoch 158/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0729e-04 - val_loss: 2.2683e-04\n",
      "Epoch 159/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0472e-04 - val_loss: 2.2501e-04\n",
      "Epoch 160/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 24ms/step - loss: 2.0472e-04 - val_loss: 2.2413e-04\n",
      "Epoch 161/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0827e-04 - val_loss: 2.2375e-04\n",
      "Epoch 162/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0839e-04 - val_loss: 2.2465e-04\n",
      "Epoch 163/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.0453e-04 - val_loss: 2.4254e-04\n",
      "Epoch 164/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0431e-04 - val_loss: 2.2075e-04\n",
      "Epoch 165/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0642e-04 - val_loss: 2.2336e-04\n",
      "Epoch 166/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1089e-04 - val_loss: 2.4264e-04\n",
      "Epoch 167/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0709e-04 - val_loss: 2.4197e-04\n",
      "Epoch 168/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1020e-04 - val_loss: 2.5845e-04\n",
      "Epoch 169/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1307e-04 - val_loss: 2.7290e-04\n",
      "Epoch 170/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1491e-04 - val_loss: 3.0383e-04\n",
      "Epoch 171/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1843e-04 - val_loss: 3.3261e-04\n",
      "Epoch 172/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1780e-04 - val_loss: 3.0798e-04\n",
      "Epoch 173/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 24ms/step - loss: 2.1405e-04 - val_loss: 2.8668e-04\n",
      "Epoch 174/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 28ms/step - loss: 2.1237e-04 - val_loss: 2.7517e-04\n",
      "Epoch 175/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1236e-04 - val_loss: 2.9498e-04\n",
      "Epoch 176/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1216e-04 - val_loss: 2.9571e-04\n",
      "Epoch 177/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1434e-04 - val_loss: 3.0361e-04\n",
      "Epoch 178/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1991e-04 - val_loss: 2.8401e-04\n",
      "Epoch 179/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2863e-04 - val_loss: 3.0960e-04\n",
      "Epoch 180/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2147e-04 - val_loss: 3.3159e-04\n",
      "Epoch 181/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1672e-04 - val_loss: 3.3359e-04\n",
      "Epoch 182/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1317e-04 - val_loss: 3.1634e-04\n",
      "Epoch 183/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1372e-04 - val_loss: 3.4407e-04\n",
      "Epoch 184/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1333e-04 - val_loss: 3.2697e-04\n",
      "Epoch 185/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1564e-04 - val_loss: 3.0681e-04\n",
      "Epoch 186/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1366e-04 - val_loss: 3.4048e-04\n",
      "Epoch 187/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1671e-04 - val_loss: 3.2180e-04\n",
      "Epoch 188/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2358e-04 - val_loss: 3.3868e-04\n",
      "Epoch 189/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1903e-04 - val_loss: 3.2371e-04\n",
      "Epoch 190/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1251e-04 - val_loss: 2.9581e-04\n",
      "Epoch 191/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0945e-04 - val_loss: 2.4566e-04\n",
      "Epoch 192/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0920e-04 - val_loss: 2.8771e-04\n",
      "Epoch 193/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0731e-04 - val_loss: 2.6310e-04\n",
      "Epoch 194/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0799e-04 - val_loss: 2.3723e-04\n",
      "Epoch 195/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.1079e-04 - val_loss: 2.4397e-04\n",
      "Epoch 196/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1211e-04 - val_loss: 2.9568e-04\n",
      "Epoch 197/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2983e-04 - val_loss: 2.2879e-04\n",
      "Epoch 198/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.2666e-04 - val_loss: 2.3209e-04\n",
      "Epoch 199/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1730e-04 - val_loss: 2.2961e-04\n",
      "Epoch 200/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1219e-04 - val_loss: 2.3809e-04\n",
      "Epoch 201/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1352e-04 - val_loss: 2.3619e-04\n",
      "Epoch 202/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1975e-04 - val_loss: 2.4806e-04\n",
      "Epoch 203/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3092e-04 - val_loss: 2.7638e-04\n",
      "Epoch 204/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3383e-04 - val_loss: 3.0730e-04\n",
      "Epoch 205/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3332e-04 - val_loss: 2.8208e-04\n",
      "Epoch 206/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.3062e-04 - val_loss: 2.5406e-04\n",
      "Epoch 207/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.1937e-04 - val_loss: 2.3705e-04\n",
      "Epoch 208/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1151e-04 - val_loss: 2.2803e-04\n",
      "Epoch 209/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0816e-04 - val_loss: 2.1283e-04\n",
      "Epoch 210/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0368e-04 - val_loss: 2.1724e-04\n",
      "Epoch 211/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0492e-04 - val_loss: 2.2027e-04\n",
      "Epoch 212/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0248e-04 - val_loss: 2.3464e-04\n",
      "Epoch 213/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0298e-04 - val_loss: 2.1481e-04\n",
      "Epoch 214/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0207e-04 - val_loss: 2.1364e-04\n",
      "Epoch 215/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0342e-04 - val_loss: 2.2664e-04\n",
      "Epoch 216/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0194e-04 - val_loss: 2.3126e-04\n",
      "Epoch 217/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9576e-04 - val_loss: 2.3189e-04\n",
      "Epoch 218/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9556e-04 - val_loss: 2.3325e-04\n",
      "Epoch 219/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.0114e-04 - val_loss: 2.8133e-04\n",
      "Epoch 220/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0168e-04 - val_loss: 2.2302e-04\n",
      "Epoch 221/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9909e-04 - val_loss: 2.1372e-04\n",
      "Epoch 222/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0000e-04 - val_loss: 2.0841e-04\n",
      "Epoch 223/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0241e-04 - val_loss: 2.0918e-04\n",
      "Epoch 224/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0753e-04 - val_loss: 2.1699e-04\n",
      "Epoch 225/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0706e-04 - val_loss: 2.0951e-04\n",
      "Epoch 226/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0855e-04 - val_loss: 2.0624e-04\n",
      "Epoch 227/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0311e-04 - val_loss: 2.0734e-04\n",
      "Epoch 228/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0316e-04 - val_loss: 2.1753e-04\n",
      "Epoch 229/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0413e-04 - val_loss: 2.0805e-04\n",
      "Epoch 230/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0186e-04 - val_loss: 2.0735e-04\n",
      "Epoch 231/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0534e-04 - val_loss: 2.2162e-04\n",
      "Epoch 232/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0893e-04 - val_loss: 2.3245e-04\n",
      "Epoch 233/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0995e-04 - val_loss: 2.1709e-04\n",
      "Epoch 234/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0431e-04 - val_loss: 2.1270e-04\n",
      "Epoch 235/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0239e-04 - val_loss: 2.2800e-04\n",
      "Epoch 236/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0583e-04 - val_loss: 2.2836e-04\n",
      "Epoch 237/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1019e-04 - val_loss: 2.1968e-04\n",
      "Epoch 238/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0416e-04 - val_loss: 2.1461e-04\n",
      "Epoch 239/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9988e-04 - val_loss: 2.1562e-04\n",
      "Epoch 240/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0072e-04 - val_loss: 2.1190e-04\n",
      "Epoch 241/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0172e-04 - val_loss: 2.1977e-04\n",
      "Epoch 242/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.0003e-04 - val_loss: 2.4961e-04\n",
      "Epoch 243/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9936e-04 - val_loss: 2.1363e-04\n",
      "Epoch 244/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9565e-04 - val_loss: 2.0653e-04\n",
      "Epoch 245/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9529e-04 - val_loss: 2.5816e-04\n",
      "Epoch 246/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9636e-04 - val_loss: 2.6974e-04\n",
      "Epoch 247/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9560e-04 - val_loss: 2.3913e-04\n",
      "Epoch 248/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 29ms/step - loss: 1.9436e-04 - val_loss: 2.2889e-04\n",
      "Epoch 249/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9773e-04 - val_loss: 2.0893e-04\n",
      "Epoch 250/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9258e-04 - val_loss: 2.2398e-04\n",
      "Epoch 251/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9434e-04 - val_loss: 2.4190e-04\n",
      "Epoch 252/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9385e-04 - val_loss: 2.1001e-04\n",
      "Epoch 253/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9322e-04 - val_loss: 2.0812e-04\n",
      "Epoch 254/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9427e-04 - val_loss: 2.1188e-04\n",
      "Epoch 255/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9653e-04 - val_loss: 2.0688e-04\n",
      "Epoch 256/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0160e-04 - val_loss: 2.0354e-04\n",
      "Epoch 257/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0451e-04 - val_loss: 2.0319e-04\n",
      "Epoch 258/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9699e-04 - val_loss: 2.0261e-04\n",
      "Epoch 259/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9612e-04 - val_loss: 2.0340e-04\n",
      "Epoch 260/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9507e-04 - val_loss: 2.0513e-04\n",
      "Epoch 261/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0069e-04 - val_loss: 2.1573e-04\n",
      "Epoch 262/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0542e-04 - val_loss: 2.3093e-04\n",
      "Epoch 263/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0092e-04 - val_loss: 2.2474e-04\n",
      "Epoch 264/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0151e-04 - val_loss: 2.1116e-04\n",
      "Epoch 265/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0931e-04 - val_loss: 2.0800e-04\n",
      "Epoch 266/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1215e-04 - val_loss: 2.1398e-04\n",
      "Epoch 267/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0766e-04 - val_loss: 2.2909e-04\n",
      "Epoch 268/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0343e-04 - val_loss: 2.3069e-04\n",
      "Epoch 269/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0594e-04 - val_loss: 2.5894e-04\n",
      "Epoch 270/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1102e-04 - val_loss: 3.4561e-04\n",
      "Epoch 271/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1103e-04 - val_loss: 3.3819e-04\n",
      "Epoch 272/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1149e-04 - val_loss: 2.9882e-04\n",
      "Epoch 273/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1065e-04 - val_loss: 2.4117e-04\n",
      "Epoch 274/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1331e-04 - val_loss: 2.5905e-04\n",
      "Epoch 275/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1284e-04 - val_loss: 2.5402e-04\n",
      "Epoch 276/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0491e-04 - val_loss: 2.2163e-04\n",
      "Epoch 277/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9689e-04 - val_loss: 2.0866e-04\n",
      "Epoch 278/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 1.9115e-04 - val_loss: 2.0428e-04\n",
      "Epoch 279/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9226e-04 - val_loss: 2.0899e-04\n",
      "Epoch 280/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9251e-04 - val_loss: 2.1009e-04\n",
      "Epoch 281/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9283e-04 - val_loss: 2.0003e-04\n",
      "Epoch 282/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8843e-04 - val_loss: 2.0114e-04\n",
      "Epoch 283/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8974e-04 - val_loss: 2.0013e-04\n",
      "Epoch 284/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9227e-04 - val_loss: 2.0562e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8680e-04 - val_loss: 2.0055e-04\n",
      "Epoch 286/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8545e-04 - val_loss: 2.0157e-04\n",
      "Epoch 287/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8823e-04 - val_loss: 2.1447e-04\n",
      "Epoch 288/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8743e-04 - val_loss: 2.0434e-04\n",
      "Epoch 289/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8706e-04 - val_loss: 2.0924e-04\n",
      "Epoch 290/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 1.8832e-04 - val_loss: 2.0662e-04\n",
      "Epoch 291/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9031e-04 - val_loss: 1.9927e-04\n",
      "Epoch 292/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8924e-04 - val_loss: 2.0170e-04\n",
      "Epoch 293/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8809e-04 - val_loss: 2.0143e-04\n",
      "Epoch 294/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9047e-04 - val_loss: 2.0674e-04\n",
      "Epoch 295/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9656e-04 - val_loss: 2.0119e-04\n",
      "Epoch 296/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9266e-04 - val_loss: 2.0050e-04\n",
      "Epoch 297/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8897e-04 - val_loss: 2.0020e-04\n",
      "Epoch 298/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9223e-04 - val_loss: 1.9978e-04\n",
      "Epoch 299/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9421e-04 - val_loss: 2.1607e-04\n",
      "Epoch 300/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9609e-04 - val_loss: 2.1080e-04\n",
      "Epoch 301/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 1.9144e-04 - val_loss: 2.1284e-04\n",
      "Epoch 302/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 1.9128e-04 - val_loss: 2.0795e-04\n",
      "Epoch 303/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 1.8819e-04 - val_loss: 2.0167e-04\n",
      "Epoch 304/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 1.8792e-04 - val_loss: 2.0767e-04\n",
      "Epoch 305/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9197e-04 - val_loss: 2.0427e-04\n",
      "Epoch 306/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9222e-04 - val_loss: 2.1004e-04\n",
      "Epoch 307/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9593e-04 - val_loss: 2.2411e-04\n",
      "Epoch 308/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 2.0258e-04 - val_loss: 2.2631e-04\n",
      "Epoch 309/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9308e-04 - val_loss: 2.1772e-04\n",
      "Epoch 310/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8720e-04 - val_loss: 2.1810e-04\n",
      "Epoch 311/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 1.8833e-04 - val_loss: 2.1291e-04\n",
      "Epoch 312/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9580e-04 - val_loss: 2.2681e-04\n",
      "Epoch 313/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0364e-04 - val_loss: 2.6024e-04\n",
      "Epoch 314/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0086e-04 - val_loss: 3.2819e-04\n",
      "Epoch 315/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0718e-04 - val_loss: 4.0766e-04\n",
      "Epoch 316/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0374e-04 - val_loss: 3.9333e-04\n",
      "Epoch 317/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0470e-04 - val_loss: 3.4778e-04\n",
      "Epoch 318/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1012e-04 - val_loss: 2.8551e-04\n",
      "Epoch 319/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1806e-04 - val_loss: 2.3110e-04\n",
      "Epoch 320/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1484e-04 - val_loss: 2.1865e-04\n",
      "Epoch 321/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 2.2445e-04 - val_loss: 2.0859e-04\n",
      "Epoch 322/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 29ms/step - loss: 2.0290e-04 - val_loss: 2.0392e-04\n",
      "Epoch 323/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9846e-04 - val_loss: 2.0830e-04\n",
      "Epoch 324/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0797e-04 - val_loss: 2.0238e-04\n",
      "Epoch 325/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0414e-04 - val_loss: 1.9728e-04\n",
      "Epoch 326/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9973e-04 - val_loss: 2.0440e-04\n",
      "Epoch 327/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9821e-04 - val_loss: 2.2160e-04\n",
      "Epoch 328/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9862e-04 - val_loss: 2.0903e-04\n",
      "Epoch 329/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9935e-04 - val_loss: 2.1356e-04\n",
      "Epoch 330/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9639e-04 - val_loss: 2.1725e-04\n",
      "Epoch 331/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9669e-04 - val_loss: 2.1979e-04\n",
      "Epoch 332/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9715e-04 - val_loss: 2.1190e-04\n",
      "Epoch 333/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9996e-04 - val_loss: 2.0313e-04\n",
      "Epoch 334/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1015e-04 - val_loss: 2.0658e-04\n",
      "Epoch 335/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0406e-04 - val_loss: 2.0823e-04\n",
      "Epoch 336/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0501e-04 - val_loss: 2.1005e-04\n",
      "Epoch 337/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0487e-04 - val_loss: 2.1379e-04\n",
      "Epoch 338/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0471e-04 - val_loss: 2.0386e-04\n",
      "Epoch 339/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1048e-04 - val_loss: 2.0117e-04\n",
      "Epoch 340/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0565e-04 - val_loss: 1.9933e-04\n",
      "Epoch 341/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9537e-04 - val_loss: 2.0159e-04\n",
      "Epoch 342/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9487e-04 - val_loss: 2.0112e-04\n",
      "Epoch 343/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9660e-04 - val_loss: 2.0943e-04\n",
      "Epoch 344/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9961e-04 - val_loss: 2.1261e-04\n",
      "Epoch 345/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0002e-04 - val_loss: 2.1854e-04\n",
      "Epoch 346/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9915e-04 - val_loss: 2.8467e-04\n",
      "Epoch 347/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0864e-04 - val_loss: 3.2802e-04\n",
      "Epoch 348/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9747e-04 - val_loss: 3.1406e-04\n",
      "Epoch 349/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9551e-04 - val_loss: 2.8156e-04\n",
      "Epoch 350/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0226e-04 - val_loss: 2.6823e-04\n",
      "Epoch 351/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1169e-04 - val_loss: 2.0604e-04\n",
      "Epoch 352/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0258e-04 - val_loss: 2.1472e-04\n",
      "Epoch 353/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9567e-04 - val_loss: 2.1434e-04\n",
      "Epoch 354/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9204e-04 - val_loss: 2.1603e-04\n",
      "Epoch 355/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9248e-04 - val_loss: 2.0151e-04\n",
      "Epoch 356/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9046e-04 - val_loss: 2.0707e-04\n",
      "Epoch 357/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8596e-04 - val_loss: 2.2734e-04\n",
      "Epoch 358/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8605e-04 - val_loss: 3.0412e-04\n",
      "Epoch 359/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 23ms/step - loss: 1.9280e-04 - val_loss: 3.4707e-04\n",
      "Epoch 360/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9612e-04 - val_loss: 2.9741e-04\n",
      "Epoch 361/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9513e-04 - val_loss: 2.3619e-04\n",
      "Epoch 362/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9156e-04 - val_loss: 2.2445e-04\n",
      "Epoch 363/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9045e-04 - val_loss: 2.2525e-04\n",
      "Epoch 364/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8837e-04 - val_loss: 2.4121e-04\n",
      "Epoch 365/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8941e-04 - val_loss: 2.3780e-04\n",
      "Epoch 366/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8834e-04 - val_loss: 2.2282e-04\n",
      "Epoch 367/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.8976e-04 - val_loss: 2.2451e-04\n",
      "Epoch 368/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9330e-04 - val_loss: 2.6654e-04\n",
      "Epoch 369/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0183e-04 - val_loss: 3.5301e-04\n",
      "Epoch 370/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0732e-04 - val_loss: 3.2623e-04\n",
      "Epoch 371/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1797e-04 - val_loss: 2.4462e-04\n",
      "Epoch 372/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.1298e-04 - val_loss: 2.0669e-04\n",
      "Epoch 373/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 2.0170e-04 - val_loss: 2.1152e-04\n",
      "Epoch 374/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9532e-04 - val_loss: 2.2262e-04\n",
      "Epoch 375/1000\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 1.9635e-04 - val_loss: 2.2883e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### # Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model and get the training history with early stopping\n",
    "history = hybrid_sr_model.fit(\n",
    "    X_train_lr, \n",
    "    X_train_hr, \n",
    "    epochs=1000, \n",
    "    batch_size=4, \n",
    "    validation_data=(X_validation_lr, X_validation_hr),\n",
    "    callbacks=[early_stopping]  # Add the early stopping callback here\n",
    ")\n",
    "\n",
    "# Visualize training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc0f6b",
   "metadata": {},
   "source": [
    "## Report the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87cb51f-9703-448a-bc7e-cc5e152d396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 00:29:15.184655: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,32,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,36,36]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-07 00:29:15.392742: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[32,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,144,144]{3,2,1,0}, f32[6,32,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 00:29:19.929462: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[23,32,36,36]{3,2,1,0}, u8[0]{0}) custom-call(f32[23,32,36,36]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-03-07 00:29:20.096454: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[23,6,144,144]{3,2,1,0}, u8[0]{0}) custom-call(f32[23,32,144,144]{3,2,1,0}, f32[6,32,3,3]{3,2,1,0}, f32[6]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step\n",
      "Average PSNR on the test set: 31.559786665135753\n",
      "Average SSIM on the test set: 0.8809812\n",
      "Average SAM on the test set (in degrees): 2.266616647938358\n",
      "Average Correlation Coefficient on the test set: 0.9633994058465039\n",
      "Average ERGAS on the test set: 3.8812210535120037\n",
      "Average RMSE: 0.027451795\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate PSNR without normalization\n",
    "def psnr(y_true, y_pred):\n",
    "    max_pixel = np.max(y_true)  # Use the actual max value from y_true\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    if mse == 0:  # Avoid log of zero\n",
    "        return float('inf')\n",
    "    psnr_value = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    return psnr_value\n",
    "\n",
    "# Function to calculate SSIM with channel_axis\n",
    "def ssim_value(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Shape mismatch: y_true shape {y_true.shape} vs y_pred shape {y_pred.shape}\")\n",
    "    \n",
    "    data_range = y_true.max() - y_true.min()  # Calculate data range from y_true\n",
    "    ssim_val = ssim(y_true, y_pred, data_range=data_range, channel_axis=-1)\n",
    "    return ssim_val\n",
    "\n",
    "# Function to calculate Correlation Coefficient\n",
    "def correlation_coefficient(y_true, y_pred):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    corr_matrix = np.corrcoef(y_true_flat, y_pred_flat)\n",
    "    corr_value = corr_matrix[0, 1]\n",
    "    return corr_value\n",
    "\n",
    "# Function to calculate Spectral Angle Mapper (SAM) in degrees\n",
    "def sam(y_true, y_pred):\n",
    "    y_true_reshaped = y_true.reshape(-1, y_true.shape[-1])\n",
    "    y_pred_reshaped = y_pred.reshape(-1, y_pred.shape[-1])\n",
    "    \n",
    "    non_zero_mask = (np.linalg.norm(y_true_reshaped, axis=1) > 1e-10) & (np.linalg.norm(y_pred_reshaped, axis=1) > 1e-10)\n",
    "    dot_product = np.sum(y_true_reshaped[non_zero_mask] * y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    norm_true = np.linalg.norm(y_true_reshaped[non_zero_mask], axis=1)\n",
    "    norm_pred = np.linalg.norm(y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        angles = np.arccos(np.clip(dot_product / (norm_true * norm_pred), -1.0, 1.0))\n",
    "    \n",
    "    if angles.size > 0:\n",
    "        sam_value_degrees = np.mean(angles) * (180 / np.pi)\n",
    "    else:\n",
    "        sam_value_degrees = 0\n",
    "    \n",
    "    return sam_value_degrees\n",
    "\n",
    "# Function to normalize the images\n",
    "def normalize(image):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    return (image - min_val) / (max_val - min_val)  # Normalize to [0, 1]\n",
    "\n",
    "# Function to calculate Root Mean Squared Error (RMSE) for hyperspectral images (normalized)\n",
    "def rmse_bandwise(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\"Shape mismatch between true and predicted images.\")\n",
    "    \n",
    "    bands = y_true.shape[-1]\n",
    "    rmse_per_band = []\n",
    "\n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        \n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)\n",
    "        rmse_band_value = np.sqrt(mse_band)\n",
    "        rmse_per_band.append(rmse_band_value)\n",
    "\n",
    "    # Normalize RMSE by the maximum value in y_true across all bands\n",
    "    max_value = np.max(y_true)\n",
    "    normalized_rmse = np.mean(rmse_per_band) / max_value\n",
    "    return normalized_rmse\n",
    "\n",
    "# Function to calculate ERGAS\n",
    "def ergas(y_true, y_pred, scale):\n",
    "    bands = y_true.shape[-1]\n",
    "    ergas_value = 0\n",
    "    \n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        mean_band_true = np.mean(band_true)\n",
    "        \n",
    "        # Calculate RMSE for the band without using a separate function\n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)  # Mean Squared Error for the band\n",
    "        rmse_band = np.sqrt(mse_band)  # Root Mean Squared Error for the band\n",
    "        \n",
    "        ergas_value += (rmse_band / mean_band_true) ** 2\n",
    "    \n",
    "    ergas_value = 100 * (1 / scale) * np.sqrt(ergas_value / bands)\n",
    "    return ergas_value\n",
    "\n",
    "# Assuming hybrid_sr_model is trained, and X_test_lr, X_test_hr are defined\n",
    "predicted_hr_images = hybrid_sr_model.predict(X_test_lr)\n",
    "downscale_factor = 4  # ERGAS downscale factor\n",
    "\n",
    "# Validate shapes match for test and predictions\n",
    "if predicted_hr_images.shape != X_test_hr.shape:\n",
    "    raise ValueError(f\"Shape mismatch: predicted_hr_images shape {predicted_hr_images.shape} vs X_test_hr shape {X_test_hr.shape}\")\n",
    "\n",
    "# Calculate metrics per test sample\n",
    "psnr_values, ssim_values, cc_values, sam_values, ergas_values, rmse_values = [], [], [], [], [], []\n",
    "\n",
    "for i in range(len(X_test_hr)):\n",
    "    psnr_values.append(psnr(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ssim_values.append(ssim_value(X_test_hr[i], predicted_hr_images[i]))\n",
    "    cc_values.append(correlation_coefficient(X_test_hr[i], predicted_hr_images[i]))\n",
    "    sam_values.append(sam(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ergas_values.append(ergas(X_test_hr[i], predicted_hr_images[i], downscale_factor))\n",
    "    rmse_values.append(rmse_bandwise(X_test_hr[i], predicted_hr_images[i]))\n",
    "\n",
    "# Average metrics\n",
    "average_psnr = np.mean(psnr_values)\n",
    "average_ssim = np.mean(ssim_values)\n",
    "average_cc = np.mean(cc_values)\n",
    "average_sam = np.mean(sam_values)\n",
    "average_ergas = np.mean(ergas_values)\n",
    "average_rmse = np.mean(rmse_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Average PSNR on the test set:\", average_psnr)\n",
    "print(\"Average SSIM on the test set:\", average_ssim)\n",
    "print(\"Average SAM on the test set (in degrees):\", average_sam)\n",
    "print(\"Average Correlation Coefficient on the test set:\", average_cc)\n",
    "print(\"Average ERGAS on the test set:\", average_ergas)\n",
    "print(\"Average RMSE:\", average_rmse)  # Indicate RMSE is normalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

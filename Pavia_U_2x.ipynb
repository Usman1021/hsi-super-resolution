{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8d36ef-2dff-4215-b798-08f878057a3d",
   "metadata": {},
   "source": [
    "## Hybrid Deep Learning Model for HyperspectralvImage Super-resolution with Gradient-Aware Loss Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67e0d5a-f4e5-472a-a2f2-e0c16e43f24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 14:06:10.247000: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-18 14:06:10.262613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739880370.278634 1066063 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739880370.283600 1066063 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 14:06:10.300496: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from spectral import open_image\n",
    "from scipy.io import loadmat \n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, Activation, Add, Concatenate, Input\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Input, UpSampling2D, Concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f646b955-67fe-4c08-8287-fc146607c52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in loaded .mat file: dict_keys(['__header__', '__version__', '__globals__', 'paviaU'])\n",
      "Hyperspectral image shape: (610, 340, 103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739880374.994782 1066063 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_hr shape: (140, 144, 144, 6)\n",
      "X_validation_hr shape: (20, 144, 144, 6)\n",
      "X_test_hr shape: (40, 144, 144, 6)\n",
      "X_train_lr shape: (140, 72, 72, 6)\n",
      "X_validation_lr shape: (20, 72, 72, 6)\n",
      "X_test_lr shape: (40, 72, 72, 6)\n"
     ]
    }
   ],
   "source": [
    "# Set all seeds for reproducibility\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# Ensure TensorFlow uses deterministic operations\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Load the Pavia dataset\n",
    "try:\n",
    "    data = loadmat(\"PaviaU.mat\")  # Ensure that the file path is correct\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading .mat file: {e}\")\n",
    "\n",
    "# Access the hyperspectral image using the correct key 'paviaU'\n",
    "print(\"Keys in loaded .mat file:\", data.keys())\n",
    "if 'paviaU' in data:\n",
    "    hyperspectral_image = data['paviaU']\n",
    "else:\n",
    "    raise KeyError(\"'paviaU' not found in the .mat file.\")\n",
    "\n",
    "# Check the shape of the hyperspectral image\n",
    "print(\"Hyperspectral image shape:\", hyperspectral_image.shape)\n",
    "\n",
    "# Convert to float32 for TensorFlow operations\n",
    "hyperspectral_image = hyperspectral_image.astype(np.float32)\n",
    "\n",
    "# Parameters\n",
    "patch_size = (144, 144)  # Size of patches to extract\n",
    "test_size = 0.2  # Proportion of data for testing\n",
    "validation_size = 0.1  # Proportion of data for validation\n",
    "downscale_factor = 2  # Factor to downscale patches\n",
    "nodata_value = -1  # Value that indicates \"no data\"\n",
    "group_size = 6  # Group size for spectral bands\n",
    "overlap_size = 2  # Overlap size for grouped bands\n",
    "\n",
    "# Function to group bands into overlapping subgroups\n",
    "def group_bands_with_overlap(data, group_size=6, overlap_size=2):\n",
    "    height, width, bands = data.shape\n",
    "    step_size = group_size - overlap_size  # Calculate step size based on overlap\n",
    "    grouped_data = []\n",
    "\n",
    "    # Create overlapping groups of bands\n",
    "    for g in range(0, bands - group_size + 1, step_size):\n",
    "        group = data[:, :, g:g + group_size]\n",
    "        grouped_data.append(group)\n",
    "    \n",
    "    return np.array(grouped_data)\n",
    "\n",
    "# Extract and downscale patches from hyperspectral data\n",
    "def extract_and_downscale_patches(data, patch_size, downscale_factor, nodata_value=0):\n",
    "    patches_hr = []\n",
    "    patches_lr = []\n",
    "    height, width, bands = data.shape\n",
    "\n",
    "    for i in range(0, height - patch_size[0] + 1, patch_size[0]):\n",
    "        for j in range(0, width - patch_size[1] + 1, patch_size[1]):\n",
    "            patch_hr = data[i:i + patch_size[0], j:j + patch_size[1], :]\n",
    "\n",
    "            # Check for nodata_value and skip patch extraction if present\n",
    "            if np.any(patch_hr == nodata_value):\n",
    "                continue\n",
    "            \n",
    "            patch_lr = tf.image.resize(patch_hr, \n",
    "                                       [patch_size[0] // downscale_factor, patch_size[1] // downscale_factor], \n",
    "                                       method='bilinear')\n",
    "            patches_hr.append(patch_hr)\n",
    "            patches_lr.append(patch_lr.numpy())  # Convert tensor to numpy\n",
    "\n",
    "    return np.array(patches_hr), np.array(patches_lr)\n",
    "\n",
    "# Group bands into overlapping subgroups\n",
    "grouped_data = group_bands_with_overlap(hyperspectral_image, group_size=group_size, overlap_size=overlap_size)\n",
    "\n",
    "# Extract and downscale patches for all groups\n",
    "all_patches_hr = []\n",
    "all_patches_lr = []\n",
    "\n",
    "for group in grouped_data:\n",
    "    patches_hr, patches_lr = extract_and_downscale_patches(group, patch_size, downscale_factor, nodata_value=nodata_value)\n",
    "    all_patches_hr.append(patches_hr)\n",
    "    all_patches_lr.append(patches_lr)\n",
    "\n",
    "# Convert lists to numpy arrays before shuffling\n",
    "all_patches_hr = np.array(all_patches_hr)\n",
    "all_patches_lr = np.array(all_patches_lr)\n",
    "\n",
    "# Concatenate patches from all groups\n",
    "all_patches_hr = np.concatenate(all_patches_hr, axis=0)\n",
    "all_patches_lr = np.concatenate(all_patches_lr, axis=0)\n",
    "\n",
    "# Calculate the number of patches\n",
    "num_patches = len(all_patches_hr)\n",
    "\n",
    "# Calculate sizes for training, validation, and testing sets\n",
    "train_size = int((1 - test_size - validation_size) * num_patches)\n",
    "validation_size = int(validation_size * num_patches)\n",
    "test_size = num_patches - (train_size + validation_size)  # Explicit calculation of test size\n",
    "\n",
    "# Shuffle indices for splitting the data\n",
    "indices = np.arange(num_patches)\n",
    "np.random.shuffle(indices)\n",
    "all_patches_hr = all_patches_hr[indices]\n",
    "all_patches_lr = all_patches_lr[indices]\n",
    "\n",
    "# Split into training, validation, and testing sets\n",
    "X_train_hr, X_validation_hr, X_test_hr = np.split(all_patches_hr, [train_size, train_size + validation_size])\n",
    "X_train_lr, X_validation_lr, X_test_lr = np.split(all_patches_lr, [train_size, train_size + validation_size])\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"X_train_hr shape:\", X_train_hr.shape)\n",
    "print(\"X_validation_hr shape:\", X_validation_hr.shape)\n",
    "print(\"X_test_hr shape:\", X_test_hr.shape)\n",
    "\n",
    "print(\"X_train_lr shape:\", X_train_lr.shape)\n",
    "print(\"X_validation_lr shape:\", X_validation_lr.shape)\n",
    "print(\"X_test_lr shape:\", X_test_lr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be38a918-f8fa-4ee6-9d67-0512babe7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Spatial–Spectral Gradient Loss Function\n",
    "def spatial_spectral_gradient_loss(y_true, y_pred):\n",
    "    mse_loss = K.mean(K.square(y_true - y_pred))\n",
    "    \n",
    "    def spatial_gradient_loss(y_true, y_pred):\n",
    "        grad_y_true_x = y_true[:, :, 1:, :] - y_true[:, :, :-1, :]\n",
    "        grad_y_pred_x = y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :]\n",
    "        grad_y_true_y = y_true[:, 1:, :, :] - y_true[:, :-1, :, :]\n",
    "        grad_y_pred_y = y_pred[:, 1:, :, :] - y_pred[:, :-1, :, :]\n",
    "        \n",
    "        loss_x = K.mean(K.square(grad_y_true_x - grad_y_pred_x))\n",
    "        loss_y = K.mean(K.square(grad_y_true_y - grad_y_pred_y))\n",
    "        \n",
    "        return loss_x + loss_y\n",
    "\n",
    "    def spectral_gradient_loss(y_true, y_pred):\n",
    "        grad_y_true_spectral = y_true[:, :, :, 1:] - y_true[:, :, :, :-1]\n",
    "        grad_y_pred_spectral = y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1]\n",
    "        return K.mean(K.square(grad_y_true_spectral - grad_y_pred_spectral))\n",
    "\n",
    "    spatial_loss = spatial_gradient_loss(y_true, y_pred)\n",
    "    spectral_loss = spectral_gradient_loss(y_true, y_pred)\n",
    "    \n",
    "    total_loss = mse_loss + 0.1 * spatial_loss + 0.1 * spectral_loss\n",
    "    return total_loss\n",
    "\n",
    "# Residual Block\n",
    "def residual_block(x, filters=32):\n",
    "    res = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    res = BatchNormalization()(res)\n",
    "    res = Activation('relu')(res)\n",
    "    res = Conv2D(filters, (3, 3), padding='same')(res)\n",
    "    res = BatchNormalization()(res)\n",
    "    return Add()([x, res])\n",
    "\n",
    "# Spectral–Spatial Block\n",
    "def spectral_spatial_block(x, filters=32):\n",
    "    spatial = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    spatial = BatchNormalization()(spatial)\n",
    "    spatial = Activation('relu')(spatial)\n",
    "    \n",
    "    spectral = Conv2D(filters, (1, 1), padding='same')(x)\n",
    "    spectral = BatchNormalization()(spectral)\n",
    "    spectral = Activation('relu')(spectral)\n",
    "    \n",
    "    spatial = Conv2D(filters, (1, 1), padding='same')(spatial)\n",
    "    \n",
    "    combined = Concatenate(axis=-1)([spatial, spectral])\n",
    "    return combined\n",
    "\n",
    "# Spectral Unmixing Block\n",
    "def spectral_unmixing_block(x, num_endmembers=10):\n",
    "    x = Conv2D(num_endmembers, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    return x\n",
    "\n",
    "# General Upsampling Block (Supports Transpose and Standard Upsampling)\n",
    "def upsample_block(x, filters, scale=2, use_transpose=True):\n",
    "    if use_transpose:\n",
    "        x = Conv2DTranspose(filters, (3, 3), strides=(scale, scale), padding='same')(x)\n",
    "    else:\n",
    "        x = UpSampling2D(size=(scale, scale))(x)\n",
    "        x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Build Model with Configurable Upsampling\n",
    "def build_hybrid_sr_model(input_shape, num_endmembers=40, use_transpose=True):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(32, (9, 9), padding='same')(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    for _ in range(50):\n",
    "        x = residual_block(x)\n",
    "    \n",
    "    x = spectral_spatial_block(x)\n",
    "    \n",
    "    x_unmixed = spectral_unmixing_block(x, num_endmembers)\n",
    "    \n",
    "    x_concat = Concatenate(axis=-1)([x, x_unmixed])\n",
    "    \n",
    "    x_up = upsample_block(x_concat, filters=64, scale=2, use_transpose=use_transpose)  # 2x upscaling\n",
    " #   x_up = upsample_block(x_up, filters=32, scale=2, use_transpose=use_transpose)  # 4x upscaling\n",
    "    \n",
    "    x_out = Conv2D(input_shape[-1], (3, 3), padding='same')(x_up)\n",
    "    x_out = Activation('linear')(x_out)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x_out)\n",
    "    return model\n",
    "\n",
    "# Define input shape and build model\n",
    "input_shape = (72, 72, 6)\n",
    "num_endmembers = 40\n",
    "use_transpose = True  # Set to False if you want to use UpSampling2D instead\n",
    "\n",
    "hybrid_sr_model = build_hybrid_sr_model(input_shape, num_endmembers=num_endmembers, use_transpose=use_transpose)\n",
    "\n",
    "# Compile the model with the custom loss function\n",
    "hybrid_sr_model.compile(optimizer='adam', loss=spatial_spectral_gradient_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecace29e-d0a5-47f8-9a82-5419221f0a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739880395.841891 1066155 service.cc:148] XLA service 0x7fba40015da0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739880395.841916 1066155 service.cc:156]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2025-02-18 14:06:36.271175: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1739880397.946972 1066155 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3110499.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739880403.180911 1066155 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 77ms/step - loss: 2680415.7500 - val_loss: 2616904.7500\n",
      "Epoch 2/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2637507.2500 - val_loss: 2677935.5000\n",
      "Epoch 3/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2576587.7500 - val_loss: 2538986.2500\n",
      "Epoch 4/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2509119.5000 - val_loss: 2445487.7500\n",
      "Epoch 5/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2434546.5000 - val_loss: 2338448.7500\n",
      "Epoch 6/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2352515.2500 - val_loss: 2227730.5000\n",
      "Epoch 7/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2262496.5000 - val_loss: 2198097.2500\n",
      "Epoch 8/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2166038.2500 - val_loss: 2104262.5000\n",
      "Epoch 9/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2063201.6250 - val_loss: 2041722.3750\n",
      "Epoch 10/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1955502.0000 - val_loss: 1878926.7500\n",
      "Epoch 11/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1844147.8750 - val_loss: 1714819.6250\n",
      "Epoch 12/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1729059.5000 - val_loss: 1635289.7500\n",
      "Epoch 13/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1613560.3750 - val_loss: 1492953.3750\n",
      "Epoch 14/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1498290.6250 - val_loss: 1380821.3750\n",
      "Epoch 15/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1383850.1250 - val_loss: 1273414.2500\n",
      "Epoch 16/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1271544.6250 - val_loss: 1111553.2500\n",
      "Epoch 17/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1162566.0000 - val_loss: 983543.0000\n",
      "Epoch 18/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1057655.2500 - val_loss: 917162.6250\n",
      "Epoch 19/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 957711.5000 - val_loss: 859800.8125\n",
      "Epoch 20/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 863194.6875 - val_loss: 715037.5000\n",
      "Epoch 21/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 774979.3750 - val_loss: 672435.5625\n",
      "Epoch 22/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 693713.6875 - val_loss: 552571.8125\n",
      "Epoch 23/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 619221.8750 - val_loss: 458046.4062\n",
      "Epoch 24/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 551778.6875 - val_loss: 458134.9062\n",
      "Epoch 25/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 490883.2188 - val_loss: 409651.3125\n",
      "Epoch 26/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 436716.6875 - val_loss: 326229.9375\n",
      "Epoch 27/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 389194.8438 - val_loss: 318871.3438\n",
      "Epoch 28/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 347933.1250 - val_loss: 252676.4062\n",
      "Epoch 29/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 312151.0938 - val_loss: 284066.8125\n",
      "Epoch 30/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 281941.5625 - val_loss: 190651.5312\n",
      "Epoch 31/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 255742.4531 - val_loss: 142483.5000\n",
      "Epoch 32/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 233259.4688 - val_loss: 132267.4531\n",
      "Epoch 33/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 214964.0781 - val_loss: 114754.1641\n",
      "Epoch 34/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 199442.9531 - val_loss: 106879.8594\n",
      "Epoch 35/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 185799.5938 - val_loss: 96101.0078\n",
      "Epoch 36/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 175328.6406 - val_loss: 74879.2266\n",
      "Epoch 37/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 167550.3750 - val_loss: 97390.6094\n",
      "Epoch 38/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 160102.7969 - val_loss: 70330.1172\n",
      "Epoch 39/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 154542.9375 - val_loss: 85725.2812\n",
      "Epoch 40/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 148834.4062 - val_loss: 80633.5391\n",
      "Epoch 41/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 144816.3125 - val_loss: 55166.2891\n",
      "Epoch 42/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 143045.1875 - val_loss: 56785.6758\n",
      "Epoch 43/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 139238.2656 - val_loss: 76868.5312\n",
      "Epoch 44/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 137634.1094 - val_loss: 57928.0000\n",
      "Epoch 45/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 137152.9219 - val_loss: 57320.8008\n",
      "Epoch 46/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 131602.5938 - val_loss: 68913.2734\n",
      "Epoch 47/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 130162.3594 - val_loss: 99627.1016\n",
      "Epoch 48/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 129326.8047 - val_loss: 185354.5625\n",
      "Epoch 49/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 128324.5000 - val_loss: 277813.4375\n",
      "Epoch 50/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 125025.0859 - val_loss: 143767.9062\n",
      "Epoch 51/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 127016.7734 - val_loss: 167413.3438\n",
      "Epoch 52/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 124398.6641 - val_loss: 72530.3047\n",
      "Epoch 53/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 120081.6641 - val_loss: 150340.2812\n",
      "Epoch 54/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 116276.1328 - val_loss: 53528.9805\n",
      "Epoch 55/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 112125.3984 - val_loss: 46704.3672\n",
      "Epoch 56/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 106014.7344 - val_loss: 46926.5195\n",
      "Epoch 57/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 102607.4609 - val_loss: 48258.1484\n",
      "Epoch 58/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 100911.5391 - val_loss: 48152.9297\n",
      "Epoch 59/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 99197.1719 - val_loss: 48385.5352\n",
      "Epoch 60/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 97532.5625 - val_loss: 45591.5703\n",
      "Epoch 61/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 94754.2344 - val_loss: 51957.7383\n",
      "Epoch 62/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 94143.4922 - val_loss: 46163.0625\n",
      "Epoch 63/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 92244.4453 - val_loss: 44801.2266\n",
      "Epoch 64/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 89977.7500 - val_loss: 48740.0156\n",
      "Epoch 65/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 88967.7422 - val_loss: 47519.7109\n",
      "Epoch 66/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 87312.8906 - val_loss: 44276.3750\n",
      "Epoch 67/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 85287.8203 - val_loss: 45661.3945\n",
      "Epoch 68/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 84986.8672 - val_loss: 45613.0859\n",
      "Epoch 69/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 84939.0234 - val_loss: 49248.0820\n",
      "Epoch 70/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 85714.2812 - val_loss: 46442.6250\n",
      "Epoch 71/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 84739.8750 - val_loss: 45412.6211\n",
      "Epoch 72/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 83026.9609 - val_loss: 44370.6289\n",
      "Epoch 73/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 81897.1172 - val_loss: 44389.7227\n",
      "Epoch 74/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 80534.0938 - val_loss: 46485.8320\n",
      "Epoch 75/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 80637.3828 - val_loss: 50799.7734\n",
      "Epoch 76/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 80842.5859 - val_loss: 44171.5195\n",
      "Epoch 77/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 79638.1797 - val_loss: 49260.5117\n",
      "Epoch 78/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 80345.1484 - val_loss: 44053.0117\n",
      "Epoch 79/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 79066.0312 - val_loss: 44075.1367\n",
      "Epoch 80/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 78694.6484 - val_loss: 44442.2227\n",
      "Epoch 81/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 79234.6328 - val_loss: 43345.4531\n",
      "Epoch 82/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 79807.2969 - val_loss: 48939.4609\n",
      "Epoch 83/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 82450.3594 - val_loss: 62066.9570\n",
      "Epoch 84/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 87089.9453 - val_loss: 51879.7891\n",
      "Epoch 85/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 84138.6016 - val_loss: 102126.7500\n",
      "Epoch 86/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 82112.9922 - val_loss: 69766.1562\n",
      "Epoch 87/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 81267.8906 - val_loss: 47387.6406\n",
      "Epoch 88/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 77773.1094 - val_loss: 49368.3086\n",
      "Epoch 89/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 75912.1953 - val_loss: 45993.4375\n",
      "Epoch 90/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 75457.9688 - val_loss: 46142.9453\n",
      "Epoch 91/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 74278.2109 - val_loss: 44795.5547\n",
      "Epoch 92/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 73627.5156 - val_loss: 45313.0586\n",
      "Epoch 93/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 72570.9688 - val_loss: 44110.0859\n",
      "Epoch 94/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 72318.2422 - val_loss: 46275.0000\n",
      "Epoch 95/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 71234.0703 - val_loss: 43448.8672\n",
      "Epoch 96/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 72182.5234 - val_loss: 43440.8047\n",
      "Epoch 97/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 70037.0156 - val_loss: 44436.4336\n",
      "Epoch 98/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 71148.6094 - val_loss: 44609.1328\n",
      "Epoch 99/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 68948.4375 - val_loss: 45945.2422\n",
      "Epoch 100/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 69609.6875 - val_loss: 43279.9688\n",
      "Epoch 101/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 68658.8438 - val_loss: 46747.0742\n",
      "Epoch 102/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 67768.2266 - val_loss: 49075.8828\n",
      "Epoch 103/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 67205.6562 - val_loss: 47427.1680\n",
      "Epoch 104/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 68593.7266 - val_loss: 45164.9688\n",
      "Epoch 105/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 66115.0000 - val_loss: 51802.1953\n",
      "Epoch 106/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 66094.4766 - val_loss: 48745.7930\n",
      "Epoch 107/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 66983.2266 - val_loss: 42178.0039\n",
      "Epoch 108/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 66460.8828 - val_loss: 42514.5586\n",
      "Epoch 109/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 64671.6562 - val_loss: 45110.5742\n",
      "Epoch 110/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 64833.9180 - val_loss: 42143.4766\n",
      "Epoch 111/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 67808.4062 - val_loss: 41716.1758\n",
      "Epoch 112/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 64070.0000 - val_loss: 54559.8047\n",
      "Epoch 113/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 64119.9805 - val_loss: 46529.6953\n",
      "Epoch 114/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 62625.3359 - val_loss: 46782.7734\n",
      "Epoch 115/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 63160.1250 - val_loss: 47143.3984\n",
      "Epoch 116/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 62248.8047 - val_loss: 46632.3516\n",
      "Epoch 117/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 61971.7734 - val_loss: 46559.5039\n",
      "Epoch 118/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 62205.1523 - val_loss: 45174.5430\n",
      "Epoch 119/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 61087.8164 - val_loss: 45868.0078\n",
      "Epoch 120/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 61752.6211 - val_loss: 46118.9375\n",
      "Epoch 121/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 60056.2812 - val_loss: 44925.7891\n",
      "Epoch 122/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 61018.2109 - val_loss: 45490.0703\n",
      "Epoch 123/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 62027.2773 - val_loss: 54715.4766\n",
      "Epoch 124/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 70895.3750 - val_loss: 169787.8438\n",
      "Epoch 125/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 68101.4141 - val_loss: 51955.5742\n",
      "Epoch 126/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 60556.2461 - val_loss: 42008.1953\n",
      "Epoch 127/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 60235.6836 - val_loss: 45441.0352\n",
      "Epoch 128/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 59701.9727 - val_loss: 64619.4805\n",
      "Epoch 129/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 58797.9297 - val_loss: 58669.9609\n",
      "Epoch 130/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 57953.6094 - val_loss: 57284.2617\n",
      "Epoch 131/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 57279.5430 - val_loss: 52199.2812\n",
      "Epoch 132/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 56588.6719 - val_loss: 49818.6484\n",
      "Epoch 133/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 56112.0547 - val_loss: 49110.3867\n",
      "Epoch 134/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 55753.5352 - val_loss: 48112.4102\n",
      "Epoch 135/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 55430.8906 - val_loss: 46362.2695\n",
      "Epoch 136/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 55148.0938 - val_loss: 45379.2656\n",
      "Epoch 137/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 54930.8086 - val_loss: 44009.3438\n",
      "Epoch 138/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 54780.3984 - val_loss: 45293.0469\n",
      "Epoch 139/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 54342.5703 - val_loss: 44751.9062\n",
      "Epoch 140/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 54277.4141 - val_loss: 46294.1641\n",
      "Epoch 141/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 55156.3750 - val_loss: 75972.3594\n",
      "Epoch 142/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 58412.5039 - val_loss: 67387.7422\n",
      "Epoch 143/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 62244.4375 - val_loss: 94921.5234\n",
      "Epoch 144/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 58490.2266 - val_loss: 42241.5195\n",
      "Epoch 145/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 55819.9023 - val_loss: 39288.7070\n",
      "Epoch 146/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 55984.3711 - val_loss: 67197.6562\n",
      "Epoch 147/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 55735.4297 - val_loss: 78509.4844\n",
      "Epoch 148/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 54495.6211 - val_loss: 52961.0234\n",
      "Epoch 149/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 53303.7617 - val_loss: 51056.2617\n",
      "Epoch 150/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 51927.7695 - val_loss: 51266.3672\n",
      "Epoch 151/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 51725.3594 - val_loss: 62122.7188\n",
      "Epoch 152/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 51520.0977 - val_loss: 64814.6328\n",
      "Epoch 153/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 51344.7109 - val_loss: 66653.0781\n",
      "Epoch 154/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 51159.0469 - val_loss: 62015.4375\n",
      "Epoch 155/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 50839.0859 - val_loss: 59526.2422\n",
      "Epoch 156/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 50414.0977 - val_loss: 59313.7109\n",
      "Epoch 157/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 50094.6562 - val_loss: 56734.1016\n",
      "Epoch 158/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49848.7227 - val_loss: 54329.6250\n",
      "Epoch 159/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49648.0352 - val_loss: 52239.9492\n",
      "Epoch 160/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49521.6367 - val_loss: 50054.9336\n",
      "Epoch 161/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49619.2266 - val_loss: 51331.5820\n",
      "Epoch 162/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49615.9258 - val_loss: 46188.0078\n",
      "Epoch 163/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49332.3359 - val_loss: 43247.9922\n",
      "Epoch 164/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49690.0391 - val_loss: 43237.0625\n",
      "Epoch 165/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49996.4648 - val_loss: 41476.4258\n",
      "Epoch 166/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49695.2422 - val_loss: 40760.5078\n",
      "Epoch 167/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 49388.4492 - val_loss: 38565.6016\n",
      "Epoch 168/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 49181.7422 - val_loss: 38191.7734\n",
      "Epoch 169/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 50010.0273 - val_loss: 38367.4648\n",
      "Epoch 170/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49388.3867 - val_loss: 38792.4609\n",
      "Epoch 171/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 49250.3867 - val_loss: 38213.7930\n",
      "Epoch 172/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 48821.6172 - val_loss: 37868.4609\n",
      "Epoch 173/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 48420.6641 - val_loss: 41116.9883\n",
      "Epoch 174/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 48270.1797 - val_loss: 40394.8359\n",
      "Epoch 175/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 47871.2422 - val_loss: 53058.0117\n",
      "Epoch 176/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47654.5781 - val_loss: 54196.9375\n",
      "Epoch 177/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47031.3477 - val_loss: 53594.0430\n",
      "Epoch 178/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 46532.4844 - val_loss: 47345.0195\n",
      "Epoch 179/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 46211.8828 - val_loss: 43873.3828\n",
      "Epoch 180/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 46115.0898 - val_loss: 40515.4688\n",
      "Epoch 181/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 46278.3633 - val_loss: 37446.6484\n",
      "Epoch 182/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47332.2227 - val_loss: 38458.2266\n",
      "Epoch 183/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47668.1094 - val_loss: 37757.8516\n",
      "Epoch 184/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47315.3203 - val_loss: 39528.3125\n",
      "Epoch 185/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47101.9531 - val_loss: 41508.4609\n",
      "Epoch 186/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 46598.7305 - val_loss: 36752.1562\n",
      "Epoch 187/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 46043.7305 - val_loss: 37065.5234\n",
      "Epoch 188/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 45733.8086 - val_loss: 37174.7695\n",
      "Epoch 189/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 45886.8750 - val_loss: 36632.5312\n",
      "Epoch 190/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 46160.9258 - val_loss: 37011.8203\n",
      "Epoch 191/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 45396.0000 - val_loss: 36120.1445\n",
      "Epoch 192/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 45091.1797 - val_loss: 36851.6172\n",
      "Epoch 193/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 44841.0352 - val_loss: 36367.7695\n",
      "Epoch 194/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 44873.1250 - val_loss: 36411.4805\n",
      "Epoch 195/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 45266.5000 - val_loss: 41537.6992\n",
      "Epoch 196/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 45352.6094 - val_loss: 37513.0391\n",
      "Epoch 197/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 49458.3242 - val_loss: 45552.1797\n",
      "Epoch 198/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 50872.5391 - val_loss: 36708.5312\n",
      "Epoch 199/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47535.2852 - val_loss: 36415.4805\n",
      "Epoch 200/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47308.8164 - val_loss: 48617.3242\n",
      "Epoch 201/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 45229.9062 - val_loss: 42889.3828\n",
      "Epoch 202/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 44393.9336 - val_loss: 39377.1484\n",
      "Epoch 203/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 43947.0742 - val_loss: 52157.5078\n",
      "Epoch 204/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 43797.7500 - val_loss: 55626.6250\n",
      "Epoch 205/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 43748.7383 - val_loss: 50095.7617\n",
      "Epoch 206/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 43427.8125 - val_loss: 49085.9219\n",
      "Epoch 207/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42815.3086 - val_loss: 44956.5742\n",
      "Epoch 208/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42650.6836 - val_loss: 47864.4062\n",
      "Epoch 209/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42489.3711 - val_loss: 52488.2930\n",
      "Epoch 210/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 43877.9922 - val_loss: 48950.4727\n",
      "Epoch 211/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 44759.6172 - val_loss: 52280.7266\n",
      "Epoch 212/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42918.8477 - val_loss: 43774.1172\n",
      "Epoch 213/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 43112.6836 - val_loss: 40770.7500\n",
      "Epoch 214/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 43672.6211 - val_loss: 37983.1133\n",
      "Epoch 215/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42940.5859 - val_loss: 41262.0000\n",
      "Epoch 216/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 43254.8789 - val_loss: 35162.0820\n",
      "Epoch 217/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 43612.6641 - val_loss: 34777.9922\n",
      "Epoch 218/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42577.1758 - val_loss: 37244.4336\n",
      "Epoch 219/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42600.6250 - val_loss: 35503.8047\n",
      "Epoch 220/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 43323.2305 - val_loss: 35151.5820\n",
      "Epoch 221/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42795.7148 - val_loss: 37817.3516\n",
      "Epoch 222/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42971.5273 - val_loss: 37109.6953\n",
      "Epoch 223/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 44368.8984 - val_loss: 43936.4062\n",
      "Epoch 224/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 44639.6602 - val_loss: 51439.0234\n",
      "Epoch 225/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47984.3555 - val_loss: 37138.7812\n",
      "Epoch 226/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 44790.5898 - val_loss: 35203.6641\n",
      "Epoch 227/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42493.0742 - val_loss: 41598.8750\n",
      "Epoch 228/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42031.5430 - val_loss: 44574.7070\n",
      "Epoch 229/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41571.8438 - val_loss: 46565.5742\n",
      "Epoch 230/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41855.0547 - val_loss: 40282.9141\n",
      "Epoch 231/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41857.5391 - val_loss: 42532.6445\n",
      "Epoch 232/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42193.1211 - val_loss: 40942.9922\n",
      "Epoch 233/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41850.8672 - val_loss: 44060.9570\n",
      "Epoch 234/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41829.4141 - val_loss: 38221.9492\n",
      "Epoch 235/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41676.1133 - val_loss: 38441.4766\n",
      "Epoch 236/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42202.4531 - val_loss: 35858.7617\n",
      "Epoch 237/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42314.0430 - val_loss: 34757.2734\n",
      "Epoch 238/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41713.0859 - val_loss: 100575.3594\n",
      "Epoch 239/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 45639.3906 - val_loss: 68764.3828\n",
      "Epoch 240/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 54214.8203 - val_loss: 62404.1758\n",
      "Epoch 241/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 44191.2773 - val_loss: 39013.1211\n",
      "Epoch 242/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 42521.8750 - val_loss: 50362.4609\n",
      "Epoch 243/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41377.5820 - val_loss: 50081.2109\n",
      "Epoch 244/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41865.9883 - val_loss: 41104.9883\n",
      "Epoch 245/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 41013.5273 - val_loss: 34038.4023\n",
      "Epoch 246/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41216.6953 - val_loss: 44933.1641\n",
      "Epoch 247/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41890.3906 - val_loss: 85555.6328\n",
      "Epoch 248/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 47522.9922 - val_loss: 56275.7930\n",
      "Epoch 249/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 45164.7578 - val_loss: 44448.3047\n",
      "Epoch 250/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 40385.1602 - val_loss: 35724.6641\n",
      "Epoch 251/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39480.1328 - val_loss: 39270.4023\n",
      "Epoch 252/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39739.8555 - val_loss: 36050.4766\n",
      "Epoch 253/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 40019.6094 - val_loss: 39234.3086\n",
      "Epoch 254/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 40533.5547 - val_loss: 43522.4141\n",
      "Epoch 255/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41165.2188 - val_loss: 91292.6094\n",
      "Epoch 256/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 43974.6797 - val_loss: 94308.4297\n",
      "Epoch 257/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 48997.5781 - val_loss: 50033.4336\n",
      "Epoch 258/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 40876.9727 - val_loss: 37511.8281\n",
      "Epoch 259/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39360.9883 - val_loss: 35971.5078\n",
      "Epoch 260/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39933.2422 - val_loss: 35686.0078\n",
      "Epoch 261/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 40641.9688 - val_loss: 36022.1172\n",
      "Epoch 262/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 41002.3164 - val_loss: 35219.8984\n",
      "Epoch 263/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39676.8516 - val_loss: 35274.4531\n",
      "Epoch 264/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39796.2500 - val_loss: 36521.5898\n",
      "Epoch 265/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39401.3516 - val_loss: 39348.1172\n",
      "Epoch 266/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 40500.8125 - val_loss: 45870.3594\n",
      "Epoch 267/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 40769.5078 - val_loss: 39016.0234\n",
      "Epoch 268/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39106.1133 - val_loss: 46766.3750\n",
      "Epoch 269/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39128.3672 - val_loss: 61637.5742\n",
      "Epoch 270/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39585.2148 - val_loss: 60318.2734\n",
      "Epoch 271/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39090.5898 - val_loss: 57061.6758\n",
      "Epoch 272/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 38322.6602 - val_loss: 36557.7109\n",
      "Epoch 273/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 37365.6367 - val_loss: 32797.4297\n",
      "Epoch 274/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 37129.7930 - val_loss: 33343.0000\n",
      "Epoch 275/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 36387.3984 - val_loss: 40982.8086\n",
      "Epoch 276/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35926.3398 - val_loss: 49265.2656\n",
      "Epoch 277/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35863.1016 - val_loss: 56756.9492\n",
      "Epoch 278/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35884.5508 - val_loss: 52024.4180\n",
      "Epoch 279/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35602.0508 - val_loss: 47230.8047\n",
      "Epoch 280/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35360.6797 - val_loss: 51409.6914\n",
      "Epoch 281/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35195.5820 - val_loss: 48924.7617\n",
      "Epoch 282/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35057.6289 - val_loss: 55612.9570\n",
      "Epoch 283/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35074.3633 - val_loss: 47207.2734\n",
      "Epoch 284/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 34907.3086 - val_loss: 54269.8242\n",
      "Epoch 285/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35777.8594 - val_loss: 35493.1797\n",
      "Epoch 286/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35738.3750 - val_loss: 41387.6250\n",
      "Epoch 287/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 38306.5312 - val_loss: 33327.5859\n",
      "Epoch 288/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 36697.6328 - val_loss: 35060.6016\n",
      "Epoch 289/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 36160.3398 - val_loss: 37108.3359\n",
      "Epoch 290/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35565.9375 - val_loss: 33088.6602\n",
      "Epoch 291/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 35415.8906 - val_loss: 31850.5352\n",
      "Epoch 292/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34905.4883 - val_loss: 40148.3828\n",
      "Epoch 293/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 36181.9688 - val_loss: 31470.0684\n",
      "Epoch 294/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34895.6055 - val_loss: 33436.4375\n",
      "Epoch 295/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34685.0352 - val_loss: 37933.1328\n",
      "Epoch 296/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34929.2695 - val_loss: 31595.6758\n",
      "Epoch 297/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34100.5234 - val_loss: 35162.5117\n",
      "Epoch 298/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33836.4102 - val_loss: 36756.4883\n",
      "Epoch 299/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 34285.1680 - val_loss: 30848.3066\n",
      "Epoch 300/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 33712.8398 - val_loss: 33202.3828\n",
      "Epoch 301/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33625.9102 - val_loss: 32910.4023\n",
      "Epoch 302/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 33889.8672 - val_loss: 29336.8867\n",
      "Epoch 303/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33729.1523 - val_loss: 29815.5879\n",
      "Epoch 304/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 33541.0625 - val_loss: 28974.1133\n",
      "Epoch 305/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34041.2383 - val_loss: 29043.3223\n",
      "Epoch 306/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33372.2812 - val_loss: 29775.4688\n",
      "Epoch 307/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34298.7227 - val_loss: 32813.3359\n",
      "Epoch 308/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35451.2109 - val_loss: 29627.5977\n",
      "Epoch 309/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33920.1836 - val_loss: 29890.6250\n",
      "Epoch 310/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33857.0078 - val_loss: 29577.2695\n",
      "Epoch 311/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33434.8086 - val_loss: 29843.5508\n",
      "Epoch 312/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 32959.5391 - val_loss: 28828.2031\n",
      "Epoch 313/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33815.6094 - val_loss: 31634.7500\n",
      "Epoch 314/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33744.8750 - val_loss: 29525.6191\n",
      "Epoch 315/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 33226.8359 - val_loss: 28448.4629\n",
      "Epoch 316/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33223.3359 - val_loss: 28513.2188\n",
      "Epoch 317/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33956.3906 - val_loss: 29273.5410\n",
      "Epoch 318/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33227.5430 - val_loss: 33600.1211\n",
      "Epoch 319/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33565.4805 - val_loss: 29620.1191\n",
      "Epoch 320/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 39879.2812 - val_loss: 30408.4434\n",
      "Epoch 321/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34394.9766 - val_loss: 30133.5273\n",
      "Epoch 322/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 38167.0586 - val_loss: 60997.3516\n",
      "Epoch 323/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 40699.1836 - val_loss: 41447.2578\n",
      "Epoch 324/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 37148.7344 - val_loss: 46525.0312\n",
      "Epoch 325/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35125.2852 - val_loss: 31039.3281\n",
      "Epoch 326/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33077.0508 - val_loss: 38411.2422\n",
      "Epoch 327/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33231.9609 - val_loss: 39263.6523\n",
      "Epoch 328/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33381.1055 - val_loss: 32187.1660\n",
      "Epoch 329/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 32992.6914 - val_loss: 30172.2598\n",
      "Epoch 330/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34696.4727 - val_loss: 34988.5898\n",
      "Epoch 331/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33105.1680 - val_loss: 31824.7129\n",
      "Epoch 332/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34807.6992 - val_loss: 33347.0391\n",
      "Epoch 333/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35332.6016 - val_loss: 37770.9648\n",
      "Epoch 334/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 34366.7344 - val_loss: 46096.9883\n",
      "Epoch 335/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 34172.6484 - val_loss: 41307.8906\n",
      "Epoch 336/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33962.9141 - val_loss: 30736.7754\n",
      "Epoch 337/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 32943.4805 - val_loss: 47253.3125\n",
      "Epoch 338/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 34398.6367 - val_loss: 48708.7500\n",
      "Epoch 339/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 34095.5586 - val_loss: 30443.6445\n",
      "Epoch 340/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 32833.5117 - val_loss: 35576.4688\n",
      "Epoch 341/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33173.5703 - val_loss: 34792.0430\n",
      "Epoch 342/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 32732.8301 - val_loss: 28671.2969\n",
      "Epoch 343/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 31372.9707 - val_loss: 29471.8477\n",
      "Epoch 344/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 30865.9844 - val_loss: 28806.6660\n",
      "Epoch 345/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 30190.1680 - val_loss: 29174.8125\n",
      "Epoch 346/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29707.1680 - val_loss: 30153.1367\n",
      "Epoch 347/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29477.5312 - val_loss: 29637.7773\n",
      "Epoch 348/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 29257.7227 - val_loss: 28331.3398\n",
      "Epoch 349/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29203.0488 - val_loss: 27318.4883\n",
      "Epoch 350/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29241.4395 - val_loss: 27469.1719\n",
      "Epoch 351/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29977.2266 - val_loss: 27840.0469\n",
      "Epoch 352/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 30430.1836 - val_loss: 28088.5352\n",
      "Epoch 353/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 35446.8164 - val_loss: 45434.7773\n",
      "Epoch 354/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 31334.2891 - val_loss: 28776.7070\n",
      "Epoch 355/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 30485.6973 - val_loss: 27427.0625\n",
      "Epoch 356/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 29417.0371 - val_loss: 26504.4062\n",
      "Epoch 357/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28851.3242 - val_loss: 27137.4844\n",
      "Epoch 358/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28903.9180 - val_loss: 29310.6523\n",
      "Epoch 359/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29140.3555 - val_loss: 27098.6680\n",
      "Epoch 360/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29869.8633 - val_loss: 28963.8809\n",
      "Epoch 361/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 31607.9941 - val_loss: 30465.7617\n",
      "Epoch 362/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 30534.0410 - val_loss: 29096.5977\n",
      "Epoch 363/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29150.2754 - val_loss: 30456.0254\n",
      "Epoch 364/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 28742.7500 - val_loss: 26011.8789\n",
      "Epoch 365/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28159.0820 - val_loss: 26476.6250\n",
      "Epoch 366/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28393.1387 - val_loss: 28716.2305\n",
      "Epoch 367/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28195.5898 - val_loss: 26699.2070\n",
      "Epoch 368/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28552.7578 - val_loss: 29086.8496\n",
      "Epoch 369/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29194.6211 - val_loss: 27091.8867\n",
      "Epoch 370/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29379.0605 - val_loss: 26710.1309\n",
      "Epoch 371/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29062.5605 - val_loss: 26227.6777\n",
      "Epoch 372/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 27858.7168 - val_loss: 25846.3164\n",
      "Epoch 373/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 27185.4258 - val_loss: 25815.8926\n",
      "Epoch 374/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27159.8320 - val_loss: 27124.7188\n",
      "Epoch 375/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27256.9961 - val_loss: 28713.7285\n",
      "Epoch 376/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27476.5645 - val_loss: 26541.4844\n",
      "Epoch 377/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28207.6230 - val_loss: 28779.5938\n",
      "Epoch 378/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 33041.7227 - val_loss: 50497.0742\n",
      "Epoch 379/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 31328.1660 - val_loss: 33907.7383\n",
      "Epoch 380/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28526.7715 - val_loss: 30339.3398\n",
      "Epoch 381/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27325.3398 - val_loss: 25863.4941\n",
      "Epoch 382/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 27220.2734 - val_loss: 25428.0039\n",
      "Epoch 383/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27223.7070 - val_loss: 26379.5781\n",
      "Epoch 384/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26662.8770 - val_loss: 31023.0840\n",
      "Epoch 385/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26636.7910 - val_loss: 25739.3828\n",
      "Epoch 386/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26016.5352 - val_loss: 26642.1348\n",
      "Epoch 387/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26093.8926 - val_loss: 25510.8398\n",
      "Epoch 388/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25926.2266 - val_loss: 26864.2246\n",
      "Epoch 389/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26437.1250 - val_loss: 25891.7461\n",
      "Epoch 390/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26154.9316 - val_loss: 28420.9590\n",
      "Epoch 391/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 28012.1426 - val_loss: 24574.2812\n",
      "Epoch 392/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27613.6348 - val_loss: 26255.2148\n",
      "Epoch 393/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28900.1992 - val_loss: 25677.3438\n",
      "Epoch 394/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26947.4219 - val_loss: 24981.3223\n",
      "Epoch 395/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 26705.1680 - val_loss: 25663.6992\n",
      "Epoch 396/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26656.9258 - val_loss: 24595.0293\n",
      "Epoch 397/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26041.6230 - val_loss: 24853.6914\n",
      "Epoch 398/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 25735.1523 - val_loss: 24527.5430\n",
      "Epoch 399/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25502.6367 - val_loss: 24712.2617\n",
      "Epoch 400/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 25212.1973 - val_loss: 25048.4160\n",
      "Epoch 401/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25120.3184 - val_loss: 24859.3086\n",
      "Epoch 402/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25723.8516 - val_loss: 26942.4902\n",
      "Epoch 403/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26901.6562 - val_loss: 25970.8457\n",
      "Epoch 404/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27089.3262 - val_loss: 26018.2695\n",
      "Epoch 405/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 31166.6172 - val_loss: 37302.1680\n",
      "Epoch 406/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 29265.2070 - val_loss: 33033.2539\n",
      "Epoch 407/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27208.5684 - val_loss: 24890.3750\n",
      "Epoch 408/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28539.7148 - val_loss: 52617.9883\n",
      "Epoch 409/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27726.0098 - val_loss: 28911.6973\n",
      "Epoch 410/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25931.0371 - val_loss: 27401.0430\n",
      "Epoch 411/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25634.2754 - val_loss: 25784.1602\n",
      "Epoch 412/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 25470.9883 - val_loss: 24192.8320\n",
      "Epoch 413/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 24823.2832 - val_loss: 23598.2305\n",
      "Epoch 414/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24737.4668 - val_loss: 24258.7207\n",
      "Epoch 415/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24946.6230 - val_loss: 24247.1367\n",
      "Epoch 416/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25627.6797 - val_loss: 23897.5645\n",
      "Epoch 417/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 24951.7559 - val_loss: 22923.7559\n",
      "Epoch 418/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24656.6074 - val_loss: 23577.6172\n",
      "Epoch 419/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24630.4316 - val_loss: 23860.6055\n",
      "Epoch 420/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25218.6172 - val_loss: 29179.9785\n",
      "Epoch 421/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26237.5410 - val_loss: 26178.2285\n",
      "Epoch 422/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25434.4785 - val_loss: 23499.7773\n",
      "Epoch 423/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24960.1309 - val_loss: 25173.5859\n",
      "Epoch 424/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25280.0234 - val_loss: 27836.4336\n",
      "Epoch 425/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26245.2832 - val_loss: 35726.6484\n",
      "Epoch 426/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27022.4766 - val_loss: 39614.0078\n",
      "Epoch 427/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26396.4434 - val_loss: 32845.3125\n",
      "Epoch 428/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28366.5117 - val_loss: 54645.3320\n",
      "Epoch 429/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27029.6797 - val_loss: 59358.7734\n",
      "Epoch 430/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26174.5957 - val_loss: 33231.8281\n",
      "Epoch 431/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25429.3164 - val_loss: 41771.7539\n",
      "Epoch 432/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25315.8008 - val_loss: 28031.6777\n",
      "Epoch 433/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25861.0977 - val_loss: 25582.4160\n",
      "Epoch 434/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25210.6289 - val_loss: 24551.4414\n",
      "Epoch 435/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27005.0312 - val_loss: 25652.3711\n",
      "Epoch 436/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 25807.3086 - val_loss: 22459.0684\n",
      "Epoch 437/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24781.3828 - val_loss: 24177.9434\n",
      "Epoch 438/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24978.4609 - val_loss: 23092.6816\n",
      "Epoch 439/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24688.5938 - val_loss: 26015.0039\n",
      "Epoch 440/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 25361.1797 - val_loss: 22055.4883\n",
      "Epoch 441/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24823.8184 - val_loss: 23392.8066\n",
      "Epoch 442/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24136.6836 - val_loss: 22372.6562\n",
      "Epoch 443/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24147.1152 - val_loss: 25260.1055\n",
      "Epoch 444/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23834.9629 - val_loss: 22809.0605\n",
      "Epoch 445/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23849.0664 - val_loss: 23622.9023\n",
      "Epoch 446/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23821.7578 - val_loss: 27842.4004\n",
      "Epoch 447/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23634.7793 - val_loss: 27596.8945\n",
      "Epoch 448/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23756.6309 - val_loss: 23374.9648\n",
      "Epoch 449/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23542.6660 - val_loss: 22908.9375\n",
      "Epoch 450/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23553.3047 - val_loss: 23359.8789\n",
      "Epoch 451/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24152.2461 - val_loss: 25906.4883\n",
      "Epoch 452/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24328.9082 - val_loss: 26211.4941\n",
      "Epoch 453/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24716.9355 - val_loss: 24133.9688\n",
      "Epoch 454/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24278.6426 - val_loss: 24396.6055\n",
      "Epoch 455/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24961.3926 - val_loss: 25178.9844\n",
      "Epoch 456/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24921.7305 - val_loss: 25845.8320\n",
      "Epoch 457/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26053.0254 - val_loss: 25551.7207\n",
      "Epoch 458/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26583.8281 - val_loss: 35821.1016\n",
      "Epoch 459/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27754.4102 - val_loss: 29007.1602\n",
      "Epoch 460/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26528.3613 - val_loss: 26412.7344\n",
      "Epoch 461/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26599.6426 - val_loss: 63786.0000\n",
      "Epoch 462/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28790.0742 - val_loss: 54214.5312\n",
      "Epoch 463/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 27917.6895 - val_loss: 47939.5547\n",
      "Epoch 464/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25855.0742 - val_loss: 24342.4531\n",
      "Epoch 465/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24460.8320 - val_loss: 29596.1719\n",
      "Epoch 466/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24249.6934 - val_loss: 30133.1973\n",
      "Epoch 467/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24716.6445 - val_loss: 25324.5508\n",
      "Epoch 468/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24584.6270 - val_loss: 27283.2461\n",
      "Epoch 469/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24455.8164 - val_loss: 26916.8867\n",
      "Epoch 470/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 25316.9688 - val_loss: 24644.8340\n",
      "Epoch 471/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24817.5703 - val_loss: 27431.0625\n",
      "Epoch 472/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24463.4141 - val_loss: 24025.8633\n",
      "Epoch 473/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23479.7090 - val_loss: 23097.9199\n",
      "Epoch 474/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23149.8340 - val_loss: 25935.7930\n",
      "Epoch 475/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23364.1152 - val_loss: 27326.6152\n",
      "Epoch 476/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 23405.8281 - val_loss: 30538.1914\n",
      "Epoch 477/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24069.8125 - val_loss: 30399.1250\n",
      "Epoch 478/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 23368.9297 - val_loss: 23231.9180\n",
      "Epoch 479/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23242.5645 - val_loss: 23353.0117\n",
      "Epoch 480/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22471.4082 - val_loss: 21674.2852\n",
      "Epoch 481/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23093.9551 - val_loss: 23935.2324\n",
      "Epoch 482/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 22158.9902 - val_loss: 21517.5000\n",
      "Epoch 483/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22746.4238 - val_loss: 23680.7520\n",
      "Epoch 484/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 21927.6133 - val_loss: 20530.4062\n",
      "Epoch 485/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22319.2070 - val_loss: 20906.9277\n",
      "Epoch 486/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21622.2031 - val_loss: 20606.3613\n",
      "Epoch 487/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21783.0352 - val_loss: 21009.8535\n",
      "Epoch 488/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21893.9238 - val_loss: 21283.5098\n",
      "Epoch 489/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 22135.8691 - val_loss: 21067.8848\n",
      "Epoch 490/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22243.9766 - val_loss: 22230.0859\n",
      "Epoch 491/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22827.0547 - val_loss: 24287.3750\n",
      "Epoch 492/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23133.7500 - val_loss: 28275.6562\n",
      "Epoch 493/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24018.5449 - val_loss: 34412.4102\n",
      "Epoch 494/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 24489.7129 - val_loss: 45912.5547\n",
      "Epoch 495/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 28305.7539 - val_loss: 63934.4492\n",
      "Epoch 496/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 26011.4336 - val_loss: 58700.1016\n",
      "Epoch 497/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23697.2871 - val_loss: 30502.4590\n",
      "Epoch 498/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22942.9004 - val_loss: 25076.7734\n",
      "Epoch 499/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22290.5312 - val_loss: 22872.6660\n",
      "Epoch 500/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21814.8203 - val_loss: 22323.3379\n",
      "Epoch 501/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21830.6074 - val_loss: 23782.7598\n",
      "Epoch 502/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 21886.2969 - val_loss: 22907.6133\n",
      "Epoch 503/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21955.7559 - val_loss: 24184.6523\n",
      "Epoch 504/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22003.4707 - val_loss: 23930.3750\n",
      "Epoch 505/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23068.9922 - val_loss: 24117.0156\n",
      "Epoch 506/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24430.8594 - val_loss: 46319.6484\n",
      "Epoch 507/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24271.8691 - val_loss: 25282.2715\n",
      "Epoch 508/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21866.5215 - val_loss: 21438.1465\n",
      "Epoch 509/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21538.2285 - val_loss: 23433.2109\n",
      "Epoch 510/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21213.8164 - val_loss: 24123.5996\n",
      "Epoch 511/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 21244.3262 - val_loss: 24810.0215\n",
      "Epoch 512/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20885.3730 - val_loss: 24603.7988\n",
      "Epoch 513/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20974.2715 - val_loss: 23700.8438\n",
      "Epoch 514/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20486.2559 - val_loss: 23097.2344\n",
      "Epoch 515/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20586.3711 - val_loss: 23247.8711\n",
      "Epoch 516/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20462.6660 - val_loss: 23202.6406\n",
      "Epoch 517/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20335.0078 - val_loss: 21961.2305\n",
      "Epoch 518/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20949.9023 - val_loss: 20853.4863\n",
      "Epoch 519/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20561.9258 - val_loss: 23206.5664\n",
      "Epoch 520/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 22512.8340 - val_loss: 20117.9902\n",
      "Epoch 521/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21196.9160 - val_loss: 21417.6758\n",
      "Epoch 522/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21384.5430 - val_loss: 20590.2715\n",
      "Epoch 523/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20479.9648 - val_loss: 23523.2324\n",
      "Epoch 524/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20636.6348 - val_loss: 21851.3398\n",
      "Epoch 525/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20676.9062 - val_loss: 20452.6133\n",
      "Epoch 526/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20693.6660 - val_loss: 23850.5527\n",
      "Epoch 527/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22753.4727 - val_loss: 43161.2031\n",
      "Epoch 528/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22848.7383 - val_loss: 37872.2305\n",
      "Epoch 529/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23566.8633 - val_loss: 28777.6875\n",
      "Epoch 530/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21908.8438 - val_loss: 31877.0586\n",
      "Epoch 531/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22062.2949 - val_loss: 31245.5098\n",
      "Epoch 532/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21166.5703 - val_loss: 27109.2695\n",
      "Epoch 533/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21197.8516 - val_loss: 26586.9277\n",
      "Epoch 534/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20690.3066 - val_loss: 25252.7070\n",
      "Epoch 535/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21050.5449 - val_loss: 27343.7500\n",
      "Epoch 536/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21221.0156 - val_loss: 20944.0820\n",
      "Epoch 537/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 21396.0469 - val_loss: 29933.2188\n",
      "Epoch 538/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 21953.5957 - val_loss: 22755.2090\n",
      "Epoch 539/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23396.4434 - val_loss: 40276.1094\n",
      "Epoch 540/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22934.0273 - val_loss: 46590.4609\n",
      "Epoch 541/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22885.4883 - val_loss: 38148.3516\n",
      "Epoch 542/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22113.3418 - val_loss: 43698.0039\n",
      "Epoch 543/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21323.6133 - val_loss: 27855.2402\n",
      "Epoch 544/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21007.0977 - val_loss: 28627.6094\n",
      "Epoch 545/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20689.3008 - val_loss: 28870.0117\n",
      "Epoch 546/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20736.3945 - val_loss: 23339.6973\n",
      "Epoch 547/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20879.2188 - val_loss: 22707.3906\n",
      "Epoch 548/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20659.9609 - val_loss: 22428.6191\n",
      "Epoch 549/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20498.5742 - val_loss: 21649.6270\n",
      "Epoch 550/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20508.8613 - val_loss: 21364.2070\n",
      "Epoch 551/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 20859.5293 - val_loss: 23407.1250\n",
      "Epoch 552/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20479.8535 - val_loss: 21670.7773\n",
      "Epoch 553/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 20605.6133 - val_loss: 19950.7832\n",
      "Epoch 554/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20613.8398 - val_loss: 21509.8027\n",
      "Epoch 555/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21562.8848 - val_loss: 21512.9434\n",
      "Epoch 556/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22973.4512 - val_loss: 46261.9922\n",
      "Epoch 557/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22321.2656 - val_loss: 34971.0625\n",
      "Epoch 558/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21993.5762 - val_loss: 21870.3301\n",
      "Epoch 559/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20398.1621 - val_loss: 19982.0176\n",
      "Epoch 560/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20803.9551 - val_loss: 21240.3340\n",
      "Epoch 561/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20088.1816 - val_loss: 21417.1152\n",
      "Epoch 562/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20310.7090 - val_loss: 20583.3633\n",
      "Epoch 563/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20000.4746 - val_loss: 24174.7480\n",
      "Epoch 564/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20210.0059 - val_loss: 21042.3047\n",
      "Epoch 565/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19892.8086 - val_loss: 21752.7773\n",
      "Epoch 566/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19682.9141 - val_loss: 22073.9258\n",
      "Epoch 567/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20159.0703 - val_loss: 25648.7246\n",
      "Epoch 568/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21445.7969 - val_loss: 22906.4746\n",
      "Epoch 569/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 21831.3828 - val_loss: 19867.0117\n",
      "Epoch 570/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 20368.7598 - val_loss: 19395.6055\n",
      "Epoch 571/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19644.3516 - val_loss: 20395.1133\n",
      "Epoch 572/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19520.1270 - val_loss: 24405.1914\n",
      "Epoch 573/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20060.4414 - val_loss: 21991.5312\n",
      "Epoch 574/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 20683.3828 - val_loss: 25175.0039\n",
      "Epoch 575/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24195.1543 - val_loss: 27794.2441\n",
      "Epoch 576/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22209.9238 - val_loss: 21348.1543\n",
      "Epoch 577/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20866.6543 - val_loss: 22568.1523\n",
      "Epoch 578/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19845.8809 - val_loss: 24271.4883\n",
      "Epoch 579/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19897.7129 - val_loss: 20277.5039\n",
      "Epoch 580/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20002.4668 - val_loss: 21200.4844\n",
      "Epoch 581/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20514.6562 - val_loss: 22619.8848\n",
      "Epoch 582/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20439.0898 - val_loss: 26686.9688\n",
      "Epoch 583/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20135.8027 - val_loss: 22681.3164\n",
      "Epoch 584/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20216.7812 - val_loss: 19800.2637\n",
      "Epoch 585/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19914.1406 - val_loss: 21350.2363\n",
      "Epoch 586/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20753.5508 - val_loss: 23089.2812\n",
      "Epoch 587/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20132.0098 - val_loss: 23039.8887\n",
      "Epoch 588/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20235.1367 - val_loss: 39311.5977\n",
      "Epoch 589/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20003.2734 - val_loss: 25961.4375\n",
      "Epoch 590/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19657.5527 - val_loss: 27025.4902\n",
      "Epoch 591/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19525.5078 - val_loss: 22079.1973\n",
      "Epoch 592/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19991.5469 - val_loss: 24511.6660\n",
      "Epoch 593/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22223.1953 - val_loss: 44506.7695\n",
      "Epoch 594/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21250.4512 - val_loss: 28554.5352\n",
      "Epoch 595/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21148.6914 - val_loss: 45492.6406\n",
      "Epoch 596/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21444.7070 - val_loss: 27635.6660\n",
      "Epoch 597/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23807.5234 - val_loss: 100941.2656\n",
      "Epoch 598/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23100.1621 - val_loss: 55281.9492\n",
      "Epoch 599/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22020.6230 - val_loss: 22916.6660\n",
      "Epoch 600/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22064.8555 - val_loss: 21921.5508\n",
      "Epoch 601/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21565.1211 - val_loss: 33667.8594\n",
      "Epoch 602/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22314.2754 - val_loss: 43859.0547\n",
      "Epoch 603/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21710.1230 - val_loss: 23081.5156\n",
      "Epoch 604/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20672.9160 - val_loss: 20118.4531\n",
      "Epoch 605/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20724.3320 - val_loss: 20547.4004\n",
      "Epoch 606/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 20026.2051 - val_loss: 19286.3867\n",
      "Epoch 607/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19538.1680 - val_loss: 20019.2656\n",
      "Epoch 608/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20424.7031 - val_loss: 20107.0840\n",
      "Epoch 609/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20028.2930 - val_loss: 22526.9492\n",
      "Epoch 610/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19698.6387 - val_loss: 19543.7949\n",
      "Epoch 611/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 18999.6621 - val_loss: 19242.6758\n",
      "Epoch 612/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19524.4902 - val_loss: 19310.9414\n",
      "Epoch 613/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 18904.1445 - val_loss: 18658.9551\n",
      "Epoch 614/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18860.6035 - val_loss: 19228.6875\n",
      "Epoch 615/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 18780.7793 - val_loss: 18572.8945\n",
      "Epoch 616/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19548.9238 - val_loss: 21727.7910\n",
      "Epoch 617/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18824.5918 - val_loss: 18872.1289\n",
      "Epoch 618/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18969.8789 - val_loss: 21313.5039\n",
      "Epoch 619/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19123.6094 - val_loss: 22649.9551\n",
      "Epoch 620/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21472.3633 - val_loss: 59655.5625\n",
      "Epoch 621/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20996.5449 - val_loss: 29076.5879\n",
      "Epoch 622/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22303.1621 - val_loss: 25648.0938\n",
      "Epoch 623/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20787.8652 - val_loss: 23402.9570\n",
      "Epoch 624/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22884.7832 - val_loss: 57531.0703\n",
      "Epoch 625/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 24582.3926 - val_loss: 26356.4590\n",
      "Epoch 626/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 21238.9160 - val_loss: 25698.1562\n",
      "Epoch 627/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20208.4375 - val_loss: 52474.9688\n",
      "Epoch 628/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 20035.7383 - val_loss: 29275.4941\n",
      "Epoch 629/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19372.2168 - val_loss: 27343.5098\n",
      "Epoch 630/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19978.4355 - val_loss: 25602.8613\n",
      "Epoch 631/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19349.7988 - val_loss: 44485.2930\n",
      "Epoch 632/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 19206.1777 - val_loss: 36992.1328\n",
      "Epoch 633/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19039.3145 - val_loss: 36596.0938\n",
      "Epoch 634/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19169.0625 - val_loss: 37162.0781\n",
      "Epoch 635/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19116.9863 - val_loss: 32786.6133\n",
      "Epoch 636/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18913.6055 - val_loss: 30142.5840\n",
      "Epoch 637/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18847.2969 - val_loss: 29695.3906\n",
      "Epoch 638/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18949.8906 - val_loss: 29451.3223\n",
      "Epoch 639/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19019.6250 - val_loss: 37977.4531\n",
      "Epoch 640/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18920.6367 - val_loss: 38930.5078\n",
      "Epoch 641/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18989.8594 - val_loss: 37000.9922\n",
      "Epoch 642/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18978.0430 - val_loss: 29189.6094\n",
      "Epoch 643/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18643.6504 - val_loss: 41144.3438\n",
      "Epoch 644/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18739.2227 - val_loss: 34446.4883\n",
      "Epoch 645/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18682.3203 - val_loss: 35427.8242\n",
      "Epoch 646/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18668.6816 - val_loss: 38622.6602\n",
      "Epoch 647/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19046.5488 - val_loss: 34861.1094\n",
      "Epoch 648/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19249.9238 - val_loss: 34605.8672\n",
      "Epoch 649/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 20471.0586 - val_loss: 26176.5195\n",
      "Epoch 650/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 25204.3477 - val_loss: 223788.7031\n",
      "Epoch 651/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 23389.8066 - val_loss: 53742.6680\n",
      "Epoch 652/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21663.0059 - val_loss: 48493.0820\n",
      "Epoch 653/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 22970.8984 - val_loss: 43122.2305\n",
      "Epoch 654/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 21037.8027 - val_loss: 30010.3008\n",
      "Epoch 655/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19201.9727 - val_loss: 23493.1914\n",
      "Epoch 656/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19838.8125 - val_loss: 24642.8633\n",
      "Epoch 657/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 19342.3730 - val_loss: 29745.6152\n",
      "Epoch 658/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19368.6035 - val_loss: 47310.5859\n",
      "Epoch 659/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19076.0039 - val_loss: 35994.2500\n",
      "Epoch 660/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18704.6738 - val_loss: 26872.4160\n",
      "Epoch 661/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 19389.6055 - val_loss: 28733.3242\n",
      "Epoch 662/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18800.9473 - val_loss: 38283.2266\n",
      "Epoch 663/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18642.5430 - val_loss: 27482.5508\n",
      "Epoch 664/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18994.1582 - val_loss: 23814.2227\n",
      "Epoch 665/1000\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 18932.0508 - val_loss: 30682.4590\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### # Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model and get the training history with early stopping\n",
    "history = hybrid_sr_model.fit(\n",
    "    X_train_lr, \n",
    "    X_train_hr, \n",
    "    epochs=1000, \n",
    "    batch_size=4, \n",
    "    validation_data=(X_validation_lr, X_validation_hr),\n",
    "    callbacks=[early_stopping]  # Add the early stopping callback here\n",
    ")\n",
    "\n",
    "# Visualize training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f6bef1-abb5-4b52-bf37-31525ce1da63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Average PSNR on the test set: 36.56230972210566\n",
      "Average SSIM on the test set: 0.9620744\n",
      "Average SAM on the test set (in degrees): 2.307285634247239\n",
      "Average Correlation Coefficient on the test set: 0.9848624424136148\n",
      "Average ERGAS on the test set: 4.330103749248037\n",
      "Average RMSE: 0.015558141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def psnr(y_true, y_pred, max_pixel=None):\n",
    "    \"\"\"\n",
    "    Compute PSNR for each spectral band separately and return the average.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth image, shape (H, W, B)\n",
    "        y_pred: Super-resolved image, shape (H, W, B)\n",
    "        max_pixel: Maximum pixel value (None = use actual max from y_true)\n",
    "    \n",
    "    Returns:\n",
    "        Average PSNR across all bands\n",
    "    \"\"\"\n",
    "    if max_pixel is None:\n",
    "        max_pixel = np.max(y_true)  # Auto-detect max value if not provided\n",
    "\n",
    "    B = y_true.shape[-1]  # Number of spectral bands\n",
    "    psnr_values = []\n",
    "    \n",
    "    for i in range(B):  # Loop over bands\n",
    "        mse = np.mean((y_true[..., i] - y_pred[..., i]) ** 2)\n",
    "        if mse == 0:\n",
    "            psnr_values.append(float('inf'))  # Perfect reconstruction\n",
    "        else:\n",
    "            psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "            psnr_values.append(psnr)\n",
    "    \n",
    "    return np.mean(psnr_values)  # Average across bands\n",
    "\n",
    "# Function to calculate SSIM with channel_axis\n",
    "def ssim_value(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Shape mismatch: y_true shape {y_true.shape} vs y_pred shape {y_pred.shape}\")\n",
    "    \n",
    "    data_range = y_true.max() - y_true.min()  # Calculate data range from y_true\n",
    "    ssim_val = ssim(y_true, y_pred, data_range=data_range, channel_axis=-1)\n",
    "    return ssim_val\n",
    "\n",
    "# Function to calculate Correlation Coefficient\n",
    "def correlation_coefficient(y_true, y_pred):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    corr_matrix = np.corrcoef(y_true_flat, y_pred_flat)\n",
    "    corr_value = corr_matrix[0, 1]\n",
    "    return corr_value\n",
    "\n",
    "# Function to calculate Spectral Angle Mapper (SAM) in degrees\n",
    "def sam(y_true, y_pred):\n",
    "    y_true_reshaped = y_true.reshape(-1, y_true.shape[-1])\n",
    "    y_pred_reshaped = y_pred.reshape(-1, y_pred.shape[-1])\n",
    "    \n",
    "    non_zero_mask = (np.linalg.norm(y_true_reshaped, axis=1) > 1e-10) & (np.linalg.norm(y_pred_reshaped, axis=1) > 1e-10)\n",
    "    dot_product = np.sum(y_true_reshaped[non_zero_mask] * y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    norm_true = np.linalg.norm(y_true_reshaped[non_zero_mask], axis=1)\n",
    "    norm_pred = np.linalg.norm(y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        angles = np.arccos(np.clip(dot_product / (norm_true * norm_pred), -1.0, 1.0))\n",
    "    \n",
    "    if angles.size > 0:\n",
    "        sam_value_degrees = np.mean(angles) * (180 / np.pi)\n",
    "    else:\n",
    "        sam_value_degrees = 0\n",
    "    \n",
    "    return sam_value_degrees\n",
    "\n",
    "# Function to normalize the images\n",
    "def normalize(image):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    return (image - min_val) / (max_val - min_val)  # Normalize to [0, 1]\n",
    "\n",
    "# Function to calculate Root Mean Squared Error (RMSE) for hyperspectral images (normalized)\n",
    "def rmse_bandwise(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\"Shape mismatch between true and predicted images.\")\n",
    "    \n",
    "    bands = y_true.shape[-1]\n",
    "    rmse_per_band = []\n",
    "\n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        \n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)\n",
    "        rmse_band_value = np.sqrt(mse_band)\n",
    "        rmse_per_band.append(rmse_band_value)\n",
    "\n",
    "    # Normalize RMSE by the maximum value in y_true across all bands\n",
    "    max_value = np.max(y_true)\n",
    "    normalized_rmse = np.mean(rmse_per_band) / max_value\n",
    "    return normalized_rmse\n",
    "\n",
    "# Function to calculate ERGAS\n",
    "def ergas(y_true, y_pred, scale):\n",
    "    bands = y_true.shape[-1]\n",
    "    ergas_value = 0\n",
    "    \n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        mean_band_true = np.mean(band_true)\n",
    "        \n",
    "        # Calculate RMSE for the band without using a separate function\n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)  # Mean Squared Error for the band\n",
    "        rmse_band = np.sqrt(mse_band)  # Root Mean Squared Error for the band\n",
    "        \n",
    "        ergas_value += (rmse_band / mean_band_true) ** 2\n",
    "    \n",
    "    ergas_value = 100 * (1 / scale) * np.sqrt(ergas_value / bands)\n",
    "    return ergas_value\n",
    "\n",
    "# Assuming hybrid_sr_model is trained, and X_test_lr, X_test_hr are defined\n",
    "predicted_hr_images = hybrid_sr_model.predict(X_test_lr, batch_size=4)\n",
    "\n",
    "downscale_factor = 2 # ERGAS downscale factor\n",
    "\n",
    "# Validate shapes match for test and predictions\n",
    "if predicted_hr_images.shape != X_test_hr.shape:\n",
    "    raise ValueError(f\"Shape mismatch: predicted_hr_images shape {predicted_hr_images.shape} vs X_test_hr shape {X_test_hr.shape}\")\n",
    "\n",
    "# Calculate metrics per test sample\n",
    "psnr_values, ssim_values, cc_values, sam_values, ergas_values, rmse_values = [], [], [], [], [], []\n",
    "\n",
    "for i in range(len(X_test_hr)):\n",
    "    psnr_values.append(psnr(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ssim_values.append(ssim_value(X_test_hr[i], predicted_hr_images[i]))\n",
    "    cc_values.append(correlation_coefficient(X_test_hr[i], predicted_hr_images[i]))\n",
    "    sam_values.append(sam(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ergas_values.append(ergas(X_test_hr[i], predicted_hr_images[i], downscale_factor))\n",
    "    rmse_values.append(rmse_bandwise(X_test_hr[i], predicted_hr_images[i]))\n",
    "\n",
    "# Average metrics\n",
    "average_psnr = np.mean(psnr_values)\n",
    "average_ssim = np.mean(ssim_values)\n",
    "average_cc = np.mean(cc_values)\n",
    "average_sam = np.mean(sam_values)\n",
    "average_ergas = np.mean(ergas_values)\n",
    "average_rmse = np.mean(rmse_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Average PSNR on the test set:\", average_psnr)\n",
    "print(\"Average SSIM on the test set:\", average_ssim)\n",
    "print(\"Average SAM on the test set (in degrees):\", average_sam)\n",
    "print(\"Average Correlation Coefficient on the test set:\", average_cc)\n",
    "print(\"Average ERGAS on the test set:\", average_ergas)\n",
    "print(\"Average RMSE:\", average_rmse)  # Indicate RMSE is normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0642c8b-d5d3-4633-bf42-37f2fa7b38de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a55521-d6dc-43e2-b12e-ef6b63efe31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb2dbb-ec2e-40d7-9964-ae20e8d65710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003ae40-b7b8-4bb5-a5a6-bad709cbac3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b161859-007e-4f28-9138-8ba13df20515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15b7ca-6eff-48ae-beec-ade680efff77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

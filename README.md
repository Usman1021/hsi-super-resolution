# Hybrid Deep Learning Model for Hyperspectral Image Super-resolution with Gradient-Aware Loss Optimization

Despite the significant success of super-resolution (SR) methods for natural images, achieving super-resolution for hyperspectral (HS) remote sensing images remains challenging due to their high spectral dimensionality. Additionally, existing hybrid SR methods commonly depend on fusing data from panchromatic or RGB images. However, this approach requires that the paired images be precisely aligned, which is often challenging to achieve in real-world applications. To address this challenge, we introduce a novel hybrid deep learning model specifically designed for single-image super-resolution, which enhances the spatial resolution of hyperspectral images without relying on auxiliary information. In particular, the model combines residual learning with a spectral-spatial fusion mechanism and spectral unmixing to effectively enhance both spatial resolution and spectral integrity. In addition, we employ a custom Spatial-Spectral Gradient Loss function, which integrates reconstruction loss with spatial and spectral gradient losses, guiding the model to accurately reconstruct gradients across both spatial and spectral dimensions. Experiments on three public remote sensing hyperspectral datasets demonstrate the feasibility and superiority of the proposed method in terms of spectral fidelity, outperforming several existing SR methods by delivering higher quality in both reconstruction and spectral accuracy.

[IEEE Xplore - Recent Issues](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8859)

